{
  "updated": "2025-06-12T04:24:13.791138+00:00",
  "top_stories": [
    {
      "id": "65841714a0e2ba7133ba6cb98e4e649e",
      "source_id": "arxiv_ai",
      "source": "cs.AI updates on arXiv.org",
      "category": "Research",
      "title": "Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism",
      "url": "https://arxiv.org/abs/2506.09176",
      "description": "arXiv:2506.09176v1 Announce Type: new \nAbstract: Interactive Imitation Learning (IIL) allows agents to acquire desired behaviors through human interventions, but current methods impose high cognitive demands on human supervisors. We propose the Adaptive Intervention Mechanism (AIM), a novel robot-gated IIL algorithm that learns an adaptive criterion for requesting human demonstrations. AIM utilizes a proxy Q-function to mimic the human intervention rule and adjusts intervention requests based on",
      "published_date": "2025-06-12T04:00:00+00:00",
      "collected_at": "2025-06-12T04:24:06.971525+00:00",
      "author": "Haoyuan Cai, Zhenghao Peng, Bolei Zhou",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "d78f50f1444c8d1965aedcb14dc11fe0",
      "source_id": "arxiv_ai",
      "source": "cs.AI updates on arXiv.org",
      "category": "Research",
      "title": "Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity",
      "url": "https://arxiv.org/abs/2506.09250",
      "description": "arXiv:2506.09250v1 Announce Type: new \nAbstract: Shojaee et al. (2025) report that Large Reasoning Models (LRMs) exhibit \"accuracy collapse\" on planning puzzles beyond certain complexity thresholds. We demonstrate that their findings primarily reflect experimental design limitations rather than fundamental reasoning failures. Our analysis reveals three critical issues: (1) Tower of Hanoi experiments systematically exceed model output token limits at reported failure points, with models explicitl",
      "published_date": "2025-06-12T04:00:00+00:00",
      "collected_at": "2025-06-12T04:24:06.971636+00:00",
      "author": "C. Opus, A. Lawsen",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "4ca98d9b05229fa75e1705fe09a5c65e",
      "source_id": "arxiv_ai",
      "source": "cs.AI updates on arXiv.org",
      "category": "Research",
      "title": "Ming-Omni: A Unified Multimodal Model for Perception and Generation",
      "url": "https://arxiv.org/abs/2506.09344",
      "description": "arXiv:2506.09344v1 Announce Type: new \nAbstract: We propose Ming-Omni, a unified multimodal model capable of processing images, text, audio, and video, while demonstrating strong proficiency in both speech and image generation. Ming-Omni employs dedicated encoders to extract tokens from different modalities, which are then processed by Ling, an MoE architecture equipped with newly proposed modality-specific routers. This design enables a single model to efficiently process and fuse multimodal in",
      "published_date": "2025-06-12T04:00:00+00:00",
      "collected_at": "2025-06-12T04:24:06.971729+00:00",
      "author": "Inclusion AI, Biao Gong, Cheng Zou, Chuanyang Zheng, Chunluan Zhou, Canxiang Yan, Chunxiang Jin, Chunjie Shen, Dandan Zheng, Fudong Wang, Furong Xu, GuangMing Yao, Jun Zhou, Jingdong Chen, Jianxin Sun, Jiajia Liu, Jianjiang Zhu, Jun Peng, Kaixiang Ji, Kaiyou Song, Kaimeng Ren, Libin Wang, Lixiang Ru, Lele Xie, Longhua Tan, Lyuxin Xue, Lan Wang, Mochen Bai, Ning Gao, Pei Chen, Qingpei Guo, Qinglong Zhang, Qiang Xu, Rui Liu, Ruijie Xiong, Sirui Gao, Tinghao Liu, Taisong Li, Weilong Chai, Xinyu Xiao, Xiaomei Wang, Xiaoxue Chen, Xiao Lu, Xiaoyu Li, Xingning Dong, Xuzheng Yu, Yi Yuan, Yuting Gao, Yunxiao Sun, Yipeng Chen, Yifei Wu, Yongjie Lyu, Ziping Ma, Zipeng Feng, Zhijiang Fang, Zhihao Qiu, Ziyuan Huang, Zhengyu He",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "c402950fdb293ce8987e879fe6a54d56",
      "source_id": "arxiv_ai",
      "source": "cs.AI updates on arXiv.org",
      "category": "Research",
      "title": "Beyond Nash Equilibrium: Bounded Rationality of LLMs and humans in Strategic Decision-making",
      "url": "https://arxiv.org/abs/2506.09390",
      "description": "arXiv:2506.09390v1 Announce Type: new \nAbstract: Large language models are increasingly used in strategic decision-making settings, yet evidence shows that, like humans, they often deviate from full rationality. In this study, we compare LLMs and humans using experimental paradigms directly adapted from behavioral game-theory research. We focus on two well-studied strategic games, Rock-Paper-Scissors and the Prisoner's Dilemma, which are well known for revealing systematic departures from ration",
      "published_date": "2025-06-12T04:00:00+00:00",
      "collected_at": "2025-06-12T04:24:06.971828+00:00",
      "author": "Kehan Zheng, Jinfeng Zhou, Hongning Wang",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "4a41b89fb436ab9dccbc8ecab75e808f",
      "source_id": "arxiv_ai",
      "source": "cs.AI updates on arXiv.org",
      "category": "Research",
      "title": "A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy",
      "url": "https://arxiv.org/abs/2506.09420",
      "description": "arXiv:2506.09420v1 Announce Type: new \nAbstract: Recent improvements in large language models (LLMs) have led many researchers to focus on building fully autonomous AI agents. This position paper questions whether this approach is the right path forward, as these autonomous systems still have problems with reliability, transparency, and understanding the actual requirements of human. We suggest a different approach: LLM-based Human-Agent Systems (LLM-HAS), where AI works with humans rather than",
      "published_date": "2025-06-12T04:00:00+00:00",
      "collected_at": "2025-06-12T04:24:06.971916+00:00",
      "author": "Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Chunyu Miao, Dongyuan Li, Aiwei Liu, Yue Zhou, Yankai Chen, Weizhi Zhang, Yangning Li, Liancheng Fang, Renhe Jiang, Philip S. Yu",
      "source_priority": 1,
      "score": 100
    }
  ],
  "categories": [
    "Research",
    "Media",
    "Open Source",
    "Industry"
  ]
}