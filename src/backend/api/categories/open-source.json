{
  "category": "Open Source",
  "count": 40,
  "articles": [
    {
      "id": "2d83a9cb9a328057c618264033ae1dbe",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Connecting the Dots for Better Movie Recommendations",
      "url": "https://towardsdatascience.com/connecting-the-dots-for-better-movie-recommendations/",
      "description": "Connecting the Dots for Better Movie Recommendations: Lightweight graph RAG on Rotten Tomatoes movie reviews\nThe post Connecting the Dots for Better Movie Recommendations appeared first on Towards Data Science.",
      "published_date": "2025-06-13T00:27:55+00:00",
      "collected_at": "2025-06-13T16:20:44.738098+00:00",
      "author": "Brian Godsey",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "04bff2841ad31c6f572d7fe153ed41d4",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Agentic AI 103: Building Multi-Agent Teams",
      "url": "https://towardsdatascience.com/agentic-ai-103-building-multi-agent-teams/",
      "description": "Build multi-agent teams that can automate tasks and enhance productivity.\nThe post Agentic AI 103: Building Multi-Agent Teams appeared first on Towards Data Science.",
      "published_date": "2025-06-12T19:34:10+00:00",
      "collected_at": "2025-06-13T16:20:44.738313+00:00",
      "author": "Gustavo Santos",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "7a26e350ec7d0152163a44bb1175001a",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Design Smarter Prompts and Boost Your LLM Output: Real Tricks from an AI Engineer’s Toolbox",
      "url": "https://towardsdatascience.com/boost-your-llm-outputdesign-smarter-prompts-real-tricks-from-an-ai-engineers-toolbox/",
      "description": "Not just what you ask, but how you ask it. Practical techniques for prompt engineering that deliver\nThe post Design Smarter Prompts and Boost Your LLM Output: Real Tricks from an AI Engineer’s Toolbox appeared first on Towards Data Science.",
      "published_date": "2025-06-12T18:54:58+00:00",
      "collected_at": "2025-06-13T16:20:44.738524+00:00",
      "author": "Ugo Pradère",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "5d0a0ada767700d7cc88a28b0c2d8da5",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "User Authorisation in Streamlit With OIDC and Google",
      "url": "https://towardsdatascience.com/user-authorisation-in-streamlit-with-oidc-and-google/",
      "description": "Log in to a Streamlit app with a Google email account\nThe post User Authorisation in Streamlit With OIDC and Google appeared first on Towards Data Science.",
      "published_date": "2025-06-12T16:54:07+00:00",
      "collected_at": "2025-06-13T16:20:44.738751+00:00",
      "author": "Thomas Reid",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "2a7b12e559517d107b6a58bb982d8c13",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Fine-Grained Perturbation Guidance via Attention Head Selection",
      "url": "https://arxiv.org/abs/2506.10978",
      "description": "Recent guidance methods in diffusion models steer reverse sampling by\nperturbing the model to construct an implicit weak model and guide generation\naway from it. Among these approaches, attention perturbation has demonstrated\nstrong empirical performance in unconditional scenarios where classifier-free\nguidance is not applicable. However, existing attention perturbation methods\nlack principled approaches for determining where perturbations should be\napplied, particularly in Diffusion Transformer",
      "published_date": "2025-06-12T13:59:51+00:00",
      "collected_at": "2025-06-13T16:20:43.052579+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "936f31fc98bda2bcd4d5f358e69af710",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science",
      "url": "https://arxiv.org/abs/2506.10974",
      "description": "Large Language Model (LLM) agents have shown great potential in addressing\nreal-world data science problems. LLM-driven data science agents promise to\nautomate the entire machine learning pipeline, yet their real-world\neffectiveness remains limited. Existing frameworks depend on rigid, pre-defined\nworkflows and inflexible coding strategies; consequently, they excel only on\nrelatively simple, classical problems and fail to capture the empirical\nexpertise that human practitioners bring to complex,",
      "published_date": "2025-06-12T13:59:32+00:00",
      "collected_at": "2025-06-13T16:20:43.054846+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "5bbff26f9ec82300f61da365ff122f59",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark",
      "url": "https://arxiv.org/abs/2506.10960",
      "description": "Large language models (LLMs) have been increasingly applied to automated\nharmful content detection tasks, assisting moderators in identifying policy\nviolations and improving the overall efficiency and accuracy of content review.\nHowever, existing resources for harmful content detection are predominantly\nfocused on English, with Chinese datasets remaining scarce and often limited in\nscope. We present a comprehensive, professionally annotated benchmark for\nChinese content harm detection, which cov",
      "published_date": "2025-06-12T13:57:05+00:00",
      "collected_at": "2025-06-13T16:20:43.055060+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "9cafde8b8a7555e3ba800d52f698c89f",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Decomposing MLP Activations into Interpretable Features via\n  Semi-Nonnegative Matrix Factorization",
      "url": "https://arxiv.org/abs/2506.10920",
      "description": "A central goal for mechanistic interpretability has been to identify the\nright units of analysis in large language models (LLMs) that causally explain\ntheir outputs. While early work focused on individual neurons, evidence that\nneurons often encode multiple concepts has motivated a shift toward analyzing\ndirections in activation space. A key question is how to find directions that\ncapture interpretable features in an unsupervised manner. Current methods rely\non dictionary learning with sparse au",
      "published_date": "2025-06-12T13:33:29+00:00",
      "collected_at": "2025-06-13T16:20:43.051080+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "6c940bb1aef5155d7e2fabc99e7bc290",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Magistral",
      "url": "https://arxiv.org/abs/2506.10910",
      "description": "We introduce Magistral, Mistral's first reasoning model and our own scalable\nreinforcement learning (RL) pipeline. Instead of relying on existing\nimplementations and RL traces distilled from prior models, we follow a ground\nup approach, relying solely on our own models and infrastructure. Notably, we\ndemonstrate a stack that enabled us to explore the limits of pure RL training\nof LLMs, present a simple method to force the reasoning language of the model,\nand show that RL on text data alone maint",
      "published_date": "2025-06-12T13:22:37+00:00",
      "collected_at": "2025-06-13T16:20:43.054556+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "3998518fd9cfc7664cde649cd2d86bb9",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a\n  Unified Framework",
      "url": "https://arxiv.org/abs/2506.10741",
      "description": "Generating aesthetic posters is more challenging than simple design images:\nit requires not only precise text rendering but also the seamless integration\nof abstract artistic content, striking layouts, and overall stylistic harmony.\nTo address this, we propose PosterCraft, a unified framework that abandons\nprior modular pipelines and rigid, predefined layouts, allowing the model to\nfreely explore coherent, visually compelling compositions. PosterCraft employs\na carefully designed, cascaded workf",
      "published_date": "2025-06-12T10:28:12+00:00",
      "collected_at": "2025-06-13T16:20:43.054357+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "d1bba51b852d5b0ae929c22c209e66a1",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to\n  Evolving Research Corpora",
      "url": "https://arxiv.org/abs/2506.10737",
      "description": "The rapid evolution of scientific fields introduces challenges in organizing\nand retrieving scientific literature. While expert-curated taxonomies have\ntraditionally addressed this need, the process is time-consuming and expensive.\nFurthermore, recent automatic taxonomy construction methods either (1)\nover-rely on a specific corpus, sacrificing generalizability, or (2) depend\nheavily on the general knowledge of large language models (LLMs) contained\nwithin their pre-training datasets, often over",
      "published_date": "2025-06-12T10:26:28+00:00",
      "collected_at": "2025-06-13T16:20:43.051851+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "1fc4ec3290b623615b92afe95da6707d",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Beyond True or False: Retrieval-Augmented Hierarchical Analysis of\n  Nuanced Claims",
      "url": "https://arxiv.org/abs/2506.10728",
      "description": "Claims made by individuals or entities are oftentimes nuanced and cannot be\nclearly labeled as entirely \"true\" or \"false\" -- as is frequently the case with\nscientific and political claims. However, a claim (e.g., \"vaccine A is better\nthan vaccine B\") can be dissected into its integral aspects and sub-aspects\n(e.g., efficacy, safety, distribution), which are individually easier to\nvalidate. This enables a more comprehensive, structured response that provides\na well-rounded perspective on a given",
      "published_date": "2025-06-12T10:17:45+00:00",
      "collected_at": "2025-06-13T16:20:43.052083+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "105cc7bcb4d3046a938205d469753c47",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "TeleMath: A Benchmark for Large Language Models in Telecom Mathematical\n  Problem Solving",
      "url": "https://arxiv.org/abs/2506.10674",
      "description": "The increasing adoption of artificial intelligence in telecommunications has\nraised interest in the capability of Large Language Models (LLMs) to address\ndomain-specific, mathematically intensive tasks. Although recent advancements\nhave improved the performance of LLMs in general mathematical reasoning, their\neffectiveness within specialized domains, such as signal processing, network\noptimization, and performance analysis, remains largely unexplored. To address\nthis gap, we introduce TeleMath,",
      "published_date": "2025-06-12T09:04:18+00:00",
      "collected_at": "2025-06-13T16:20:43.051590+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "f44b9f54b573fa0a32ab8f4c176ab773",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "EmbodiedGen: Towards a Generative 3D World Engine for Embodied\n  Intelligence",
      "url": "https://arxiv.org/abs/2506.10600",
      "description": "Constructing a physically realistic and accurately scaled simulated 3D world\nis crucial for the training and evaluation of embodied intelligence tasks. The\ndiversity, realism, low cost accessibility and affordability of 3D data assets\nare critical for achieving generalization and scalability in embodied AI.\nHowever, most current embodied intelligence tasks still rely heavily on\ntraditional 3D computer graphics assets manually created and annotated, which\nsuffer from high production costs and lim",
      "published_date": "2025-06-12T07:43:50+00:00",
      "collected_at": "2025-06-13T16:20:43.051340+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "a23da3466e7495d3a04feef729a4b506",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "DreamActor-H1: High-Fidelity Human-Product Demonstration Video\n  Generation via Motion-designed Diffusion Transformers",
      "url": "https://arxiv.org/abs/2506.10568",
      "description": "In e-commerce and digital marketing, generating high-fidelity human-product\ndemonstration videos is important for effective product presentation. However,\nmost existing frameworks either fail to preserve the identities of both humans\nand products or lack an understanding of human-product spatial relationships,\nleading to unrealistic representations and unnatural interactions. To address\nthese challenges, we propose a Diffusion Transformer (DiT)-based framework. Our\nmethod simultaneously preserve",
      "published_date": "2025-06-12T06:58:23+00:00",
      "collected_at": "2025-06-13T16:20:43.052840+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "4c6f175ac4fdbeb60ce5b925c15d0ca6",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven\n  Clip Generation",
      "url": "https://arxiv.org/abs/2506.10540",
      "description": "Despite rapid advancements in video generation models, generating coherent\nstorytelling videos that span multiple scenes and characters remains\nchallenging. Current methods often rigidly convert pre-generated keyframes into\nfixed-length clips, resulting in disjointed narratives and pacing issues.\nFurthermore, the inherent instability of video generation models means that\neven a single low-quality clip can significantly degrade the entire output\nanimation's logical coherence and visual continuity",
      "published_date": "2025-06-12T06:06:21+00:00",
      "collected_at": "2025-06-13T16:20:43.055491+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "c1685dfb6d0b3dcff3b54be485a863fb",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Exploring the Proportional Odds Model for Ordinal Logistic Regression",
      "url": "https://towardsdatascience.com/proportional-odds-model-for-ordinal-logistic-regression/",
      "description": "Understanding and Implementing Brant’s Tests in Ordinal Logistic Regression with Python\nThe post Exploring the Proportional Odds Model for Ordinal Logistic Regression appeared first on Towards Data Science.",
      "published_date": "2025-06-12T05:45:56+00:00",
      "collected_at": "2025-06-13T16:20:44.738952+00:00",
      "author": "JUNIOR JUMBONG",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "9063e838e64e6d653b3129520f884b40",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Can AI Truly Develop a Memory That Adapts Like Ours?",
      "url": "https://towardsdatascience.com/can-ai-truly-develop-a-memory-that-adapts-like-ours/",
      "description": "Exploring Titans: A new architecture equipping LLMs with human-inspired memory that learns and updates itself during test-time.\nThe post Can AI Truly Develop a Memory That Adapts Like Ours? appeared first on Towards Data Science.",
      "published_date": "2025-06-12T05:32:11+00:00",
      "collected_at": "2025-06-13T16:20:44.739149+00:00",
      "author": "Moulik Gupta",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "b60c248f372be8d09338700bd0b0e697",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Discovering Hierarchical Latent Capabilities of Language Models via\n  Causal Representation Learning",
      "url": "https://arxiv.org/abs/2506.10378",
      "description": "Faithful evaluation of language model capabilities is crucial for deriving\nactionable insights that can inform model development. However, rigorous causal\nevaluations in this domain face significant methodological challenges,\nincluding complex confounding effects and prohibitive computational costs\nassociated with extensive retraining. To tackle these challenges, we propose a\ncausal representation learning framework wherein observed benchmark performance\nis modeled as a linear transformation of",
      "published_date": "2025-06-12T02:07:42+00:00",
      "collected_at": "2025-06-13T16:20:43.055276+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "3de602462b42e0e2c00fc5df6a06a4b6",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Discrete Audio Tokens: More Than a Survey!",
      "url": "https://arxiv.org/abs/2506.10274",
      "description": "Discrete audio tokens are compact representations that aim to preserve\nperceptual quality, phonetic content, and speaker characteristics while\nenabling efficient storage and inference, as well as competitive performance\nacross diverse downstream tasks.They provide a practical alternative to\ncontinuous features, enabling the integration of speech and audio into modern\nlarge language models (LLMs). As interest in token-based audio processing\ngrows, various tokenization methods have emerged, and se",
      "published_date": "2025-06-11T21:35:43+00:00",
      "collected_at": "2025-06-13T16:20:43.052305+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "f6d81dda61f177f4ac4a259da522fa1d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Model Context Protocol (MCP) Tutorial: Build Your First MCP Server in 6 Steps",
      "url": "https://towardsdatascience.com/model-context-protocol-mcp-tutorial-build-your-first-mcp-server-in-6-steps/",
      "description": "A beginner-friendly tutorial of MCP architecture, with the focus on MCP server components and applications, guiding through the process of building a custom MCP server that enables code-to-diagram.\nThe post Model Context Protocol (MCP) Tutorial: Build Your First MCP Server in 6 Steps appeared first on Towards Data Science.",
      "published_date": "2025-06-11T19:40:45+00:00",
      "collected_at": "2025-06-13T16:20:44.739344+00:00",
      "author": "Destin Gong",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "68c07722e8ce23d92d28c6f82a57c3be",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Attention, Please! Revisiting Attentive Probing for Masked Image\n  Modeling",
      "url": "https://arxiv.org/abs/2506.10178",
      "description": "As fine-tuning (FT) becomes increasingly impractical at scale, probing is\nemerging as the preferred evaluation protocol for self-supervised learning\n(SSL). Yet, the standard linear probing (LP) fails to adequately reflect the\npotential of models trained with Masked Image Modeling (MIM), due to the\ndistributed nature of patch tokens. This motivates the need for attentive\nprobing, an alternative that uses attention to selectively aggregate\npatch-level features. Despite its growing adoption, attent",
      "published_date": "2025-06-11T17:10:26+00:00",
      "collected_at": "2025-06-13T16:20:43.053073+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "036d3d830f2eae87fdae67f04880d8b8",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Mobile App Development with Python",
      "url": "https://towardsdatascience.com/mobile-app-development-with-python/",
      "description": "Build iOS & Android Apps with Kivy\nThe post Mobile App Development with Python appeared first on Towards Data Science.",
      "published_date": "2025-06-11T16:55:03+00:00",
      "collected_at": "2025-06-13T16:20:44.750449+00:00",
      "author": "Mauro Di Pietro",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "732cb140e94759e87081b3ba3b69e428",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal\n  Gaussian Splatting",
      "url": "https://arxiv.org/abs/2506.09952",
      "description": "The scale diversity of point cloud data presents significant challenges in\ndeveloping unified representation learning techniques for 3D vision. Currently,\nthere are few unified 3D models, and no existing pre-training method is equally\neffective for both object- and scene-level point clouds. In this paper, we\nintroduce UniPre3D, the first unified pre-training method that can be\nseamlessly applied to point clouds of any scale and 3D models of any\narchitecture. Our approach predicts Gaussian primit",
      "published_date": "2025-06-11T13:23:21+00:00",
      "collected_at": "2025-06-13T16:20:43.053728+00:00",
      "author": "",
      "source_priority": 1,
      "score": 93
    },
    {
      "id": "8647cd9cdb434e35eec9fb9d5d10b3c7",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Audio Spectrogram Transformers Beyond the Lab",
      "url": "https://towardsdatascience.com/audio-spectrogram-transformers-beyond-the-lab/",
      "description": "A recipe for building a portable soundscape monitoring app with AudioMoth, Raspberry Pi, and a decent dose of deep learning.\nThe post Audio Spectrogram Transformers Beyond the Lab appeared first on Towards Data Science.",
      "published_date": "2025-06-10T23:47:29+00:00",
      "collected_at": "2025-06-13T16:20:44.750702+00:00",
      "author": "Maciej Adamiak",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "670434083c4a15bec64ebb9e2cdcc44c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Automate Models Training: An MLOps Pipeline with Tekton and Buildpacks",
      "url": "https://towardsdatascience.com/automate-models-training-an-mlops-pipeline-with-tekton-and-buildpacks/",
      "description": "A step-by-step guide to containerizing and orchestrating an ML training workflow without the Dockerfile headache, using a lightweight GPT-2 example.\nThe post Automate Models Training: An MLOps Pipeline with Tekton and Buildpacks appeared first on Towards Data Science.",
      "published_date": "2025-06-10T23:37:18+00:00",
      "collected_at": "2025-06-13T16:20:44.750916+00:00",
      "author": "Sylvain Kalache",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "14d58c32a594dab10314ce70e770deaf",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "10,000x Faster Bayesian Inference: Multi-GPU SVI vs. Traditional MCMC",
      "url": "https://towardsdatascience.com/10000x-faster-bayesian-inference-multi-gpu-svi-vs-traditional-mcmc/",
      "description": "Using GPU acceleration to speed up Bayesian Inference from months to minutes... \nThe post 10,000x Faster Bayesian Inference: Multi-GPU SVI vs. Traditional MCMC appeared first on Towards Data Science.",
      "published_date": "2025-06-10T23:29:05+00:00",
      "collected_at": "2025-06-13T16:20:44.751116+00:00",
      "author": "Derek Tran",
      "source_priority": 3,
      "score": 92
    },
    {
      "id": "a28c0119414440455448e512f68a2418",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Token Perturbation Guidance for Diffusion Models",
      "url": "https://arxiv.org/abs/2506.10036",
      "description": "Classifier-free guidance (CFG) has become an essential component of modern\ndiffusion models to enhance both generation quality and alignment with input\nconditions. However, CFG requires specific training procedures and is limited\nto conditional generation. To address these limitations, we propose Token\nPerturbation Guidance (TPG), a novel method that applies perturbation matrices\ndirectly to intermediate token representations within the diffusion network.\nTPG employs a norm-preserving shuffling",
      "published_date": "2025-06-10T17:25:46+00:00",
      "collected_at": "2025-06-13T16:20:43.054151+00:00",
      "author": "",
      "source_priority": 1,
      "score": 92
    },
    {
      "id": "50915c04bf618d568192a3eb44ce6fec",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Applications of Density Estimation to Legal Theory",
      "url": "https://towardsdatascience.com/applications-of-density-estimation-to-legal-theory/",
      "description": "A brief analysis using density estimation to compare the two-verdict and three-verdict systems.\nThe post Applications of Density Estimation to Legal Theory appeared first on Towards Data Science.",
      "published_date": "2025-06-10T16:36:24+00:00",
      "collected_at": "2025-06-13T16:20:44.751314+00:00",
      "author": "Jimin Kang",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "247080e80e8edd61863173b9d9f4ac59",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated\n  Video Streams",
      "url": "https://arxiv.org/abs/2506.08862",
      "description": "Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams\nis crucial for numerous real-world applications. However, existing methods\nstruggle to jointly address three key challenges: 1) processing uncalibrated\ninputs in real time, 2) accurately modeling dynamic scene evolution, and 3)\nmaintaining long-term stability and computational efficiency. To this end, we\nintroduce StreamSplat, the first fully feed-forward framework that transforms\nuncalibrated video streams of arbitrar",
      "published_date": "2025-06-10T10:52:36+00:00",
      "collected_at": "2025-06-13T16:20:43.053288+00:00",
      "author": "",
      "source_priority": 1,
      "score": 92
    },
    {
      "id": "2cba20a73aaee2108868ab012d464b99",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Mastering SQL Window Functions",
      "url": "https://towardsdatascience.com/mastering-sql-window-functions/",
      "description": "Understand how to use Window Functions to perform calculations without losing details\nThe post Mastering SQL Window Functions appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:36:15+00:00",
      "collected_at": "2025-06-13T16:20:44.751511+00:00",
      "author": "Eugenia Anello",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "f85347fb0559744e9a6053beb02e544f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Exploratory Data Analysis: Gamma Spectroscopy in Python",
      "url": "https://towardsdatascience.com/exploratory-data-analysis-gamma-spectroscopy-in-python/",
      "description": "Let’s observe the matter on the atomic level\nThe post Exploratory Data Analysis: Gamma Spectroscopy in Python appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:27:05+00:00",
      "collected_at": "2025-06-13T16:20:44.751739+00:00",
      "author": "Dmitrii Eliuseev",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "b5e500a2d2ad993b7c2a8d260dbc2196",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Bird’s-Eye View of Linear Algebra: Measure of a Map — Determinants",
      "url": "https://towardsdatascience.com/a-birds-eye-view-of-linear-algebra-measure-of-a-map-determinants/",
      "description": "We roll up our sleeves and start to deal with matrices\nThe post A Bird’s-Eye View of Linear Algebra: Measure of a Map — Determinants appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:00:27+00:00",
      "collected_at": "2025-06-13T16:20:44.751938+00:00",
      "author": "Rohit Pandey",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "8974cbf315fc128cbdcbf27fffa994ba",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How to Transition From Data Analyst to Data Scientist",
      "url": "https://towardsdatascience.com/how-to-transition-from-data-analyst-to-data-scientist/",
      "description": "Playbook on how data analysts can become data scientists\nThe post How to Transition From Data Analyst to Data Scientist appeared first on Towards Data Science.",
      "published_date": "2025-06-09T23:09:55+00:00",
      "collected_at": "2025-06-13T16:20:44.752319+00:00",
      "author": "Egor Howell",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "5bb2aa15fbc6f8e0fd06eba34a4606b2",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Trying to Stay Sane in the Age of AI",
      "url": "https://towardsdatascience.com/trying-to-stay-sane-in-the-age-of-ai/",
      "description": "A machine learning engineer’s quiet way of not losing her mind\nThe post Trying to Stay Sane in the Age of AI appeared first on Towards Data Science.",
      "published_date": "2025-06-09T22:50:40+00:00",
      "collected_at": "2025-06-13T16:20:44.752518+00:00",
      "author": "Amy Ma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "93f37a4ba94dd7229d84452a6441c9f6",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Compound AI Systems Optimization: A Survey of Methods, Challenges, and\n  Future Directions",
      "url": "https://arxiv.org/abs/2506.08234",
      "description": "Recent advancements in large language models (LLMs) and AI systems have led\nto a paradigm shift in the design and optimization of complex AI workflows. By\nintegrating multiple components, compound AI systems have become increasingly\nadept at performing sophisticated tasks. However, as these systems grow in\ncomplexity, new challenges arise in optimizing not only individual components\nbut also their interactions. While traditional optimization methods such as\nsupervised fine-tuning (SFT) and reinf",
      "published_date": "2025-06-09T17:04:14+00:00",
      "collected_at": "2025-06-13T16:20:43.053500+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "bff69df57dc22868213189637a98e9ba",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "LLM Unlearning Should Be Form-Independent",
      "url": "https://arxiv.org/abs/2506.07795",
      "description": "Large Language Model (LLM) unlearning aims to erase or suppress undesirable\nknowledge within the model, offering promise for controlling harmful or private\ninformation to prevent misuse. However, recent studies highlight its limited\nefficacy in real-world scenarios, hindering practical adoption. In this study,\nwe identify a pervasive issue underlying many downstream failures: the\neffectiveness of existing unlearning methods heavily depends on the form of\ntraining samples and frequently fails to",
      "published_date": "2025-06-09T10:21:25+00:00",
      "collected_at": "2025-06-13T16:20:43.053942+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "ba0a1d0ca488df04266d6f48441d1523",
      "source_id": "pytorch_blog",
      "source": "Blog – PyTorch",
      "category": "Open Source",
      "title": "HuggingFace Safetensors Support in PyTorch Distributed Checkpointing",
      "url": "https://pytorch.org/blog/huggingface-safetensors-support-in-pytorch-distributed-checkpointing/",
      "description": "Summary  PyTorch Distributed Checkpointing (DCP) is making investments into addressing the interoperability blockers to ensure that popular formats, like HuggingFace safetensors, can work well with PyTorch’s ecosystem. Since HuggingFace has...",
      "published_date": "2025-06-06T19:17:46+00:00",
      "collected_at": "2025-06-13T16:20:43.400082+00:00",
      "author": "Ankita George, Saurabh Mishra, Joe Cummings, Philip Bontrager, Daulet Askarov, Teja Rao, Chien-Chin Huang, Ela Krepska, Jafar Taghiyar",
      "source_priority": 2,
      "score": 88
    },
    {
      "id": "f2e2ef796ae85073f0397c059bcd40ea",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value",
      "url": "https://towardsdatascience.com/not-everything-needs-automation-5-practical-ai-agents-that-deliver-enterprise-value/",
      "description": "What actually works with AI agents inside enterprise organizations?\nThe post Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:54:12+00:00",
      "collected_at": "2025-06-13T16:20:44.752732+00:00",
      "author": "Weiwei Hu",
      "source_priority": 3,
      "score": 87
    },
    {
      "id": "3d5ee6adb52013963931f8bccef6033c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling.",
      "url": "https://towardsdatascience.com/prescriptive-modeling-unpacked-a-complete-guide-to-intervention-with-bayesian-modeling/",
      "description": "Learn how to move beyond prediction and actively make intervention through prescriptive modeling. This in-depth guide walks you through Bayesian approaches to system intervention, with practical examples in predictive maintenance.\nThe post Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling. appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:23:32+00:00",
      "collected_at": "2025-06-13T16:20:44.752923+00:00",
      "author": "Erdogan Taskesen",
      "source_priority": 3,
      "score": 86
    }
  ],
  "updated": "2025-06-13T16:20:59.958229"
}