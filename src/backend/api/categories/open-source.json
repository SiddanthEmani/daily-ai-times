{
  "category": "Open Source",
  "count": 36,
  "articles": [
    {
      "id": "48bf20a7a4efdc9c7e5830baf66ebdbc",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Animating Linear Transformations with Quiver",
      "url": "https://towardsdatascience.com/animating-linear-transformations-with-quiver/",
      "description": "A useful tool in your quiver\nThe post Animating Linear Transformations with Quiver appeared first on Towards Data Science.",
      "published_date": "2025-06-18T19:27:47+00:00",
      "collected_at": "2025-06-18T20:20:14.733655+00:00",
      "author": "Artemij Lehmann",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "00329eb786aa121236e9b37d4925a596",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Multi-Agent SQL Assistant You Can Trust with Human-in-Loop Checkpoint & LLM Cost Control",
      "url": "https://towardsdatascience.com/a-multi-agent-sql-assistant-you-can-trust-with-human-in-loop-checkpoint-llm-cost-control/",
      "description": "Your very own SQL assistant built with Streamlit, SQLite, & CrewAI\nThe post A Multi-Agent SQL Assistant You Can Trust with Human-in-Loop Checkpoint & LLM Cost Control appeared first on Towards Data Science.",
      "published_date": "2025-06-18T18:31:01+00:00",
      "collected_at": "2025-06-18T20:20:14.835907+00:00",
      "author": "Alle Sravani",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "20ca0310df8128a6de70f59c24acc8e8",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Can We Use Chess to Predict Soccer?",
      "url": "https://towardsdatascience.com/can-we-use-chess-to-predict-soccer/",
      "description": "An adaptation of Elo ratings for soccer implemented in Python\nThe post Can We Use Chess to Predict Soccer? appeared first on Towards Data Science.",
      "published_date": "2025-06-18T17:47:34+00:00",
      "collected_at": "2025-06-18T20:20:14.836148+00:00",
      "author": "Felipe Bandeira",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "3551c2b6755e595e6216290e15c45b74",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Computer Vision’s Annotation Bottleneck Is Finally Breaking",
      "url": "https://towardsdatascience.com/computer-visions-annotation-bottleneck-is-finally-breaking/",
      "description": "A Technical Deep Dive into Auto-Labeling\nThe post Computer Vision’s Annotation Bottleneck Is Finally Breaking appeared first on Towards Data Science.",
      "published_date": "2025-06-18T17:13:29+00:00",
      "collected_at": "2025-06-18T20:20:14.836357+00:00",
      "author": "TDS Brand Studio",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "7098de49c64233058ee854c576f05306",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Why Open Source is No Longer Optional — And How to Make it Work for Your Business",
      "url": "https://towardsdatascience.com/why-open-source-is-no-longer-optional-and-how-to-make-it-work-for-your-business/",
      "description": "To stay ahead, open source is the only way.\nThe post Why Open Source is No Longer Optional — And How to Make it Work for Your Business appeared first on Towards Data Science.",
      "published_date": "2025-06-18T16:01:38+00:00",
      "collected_at": "2025-06-18T20:20:14.836558+00:00",
      "author": "Laura Sellers",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "63a113be7db3662f6d0529a921d6e3c7",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Abstract Classes: A Software Engineering Concept Data Scientists Must Know To Succeed",
      "url": "https://towardsdatascience.com/abstract-classes-a-software-engineering-concept-data-scientists-must-know-to-succeed/",
      "description": "Simple concepts that differentiate a professional from amateurs.\nThe post Abstract Classes: A Software Engineering Concept Data Scientists Must Know To Succeed appeared first on Towards Data Science.",
      "published_date": "2025-06-17T22:45:07+00:00",
      "collected_at": "2025-06-18T20:20:14.836748+00:00",
      "author": "Benjamin Lee",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "e518c9d1e51cfbf728fff80b3577258d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "LLaVA on a Budget: Multimodal AI with Limited Resources",
      "url": "https://towardsdatascience.com/llava-on-a-budget-multimodal-ai-with-limited-resources/",
      "description": "Let's get started with multimodality\nThe post LLaVA on a Budget: Multimodal AI with Limited Resources appeared first on Towards Data Science.",
      "published_date": "2025-06-17T18:06:11+00:00",
      "collected_at": "2025-06-18T20:20:14.836962+00:00",
      "author": "Marcello Politi",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "46fbbad38f9c13bbcad1ecdf41de7410",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Apply Sphinx’s Functionality to Create Documentation for Your Next Data Science Project",
      "url": "https://towardsdatascience.com/apply-sphinxs-functionality-to-create-documentation-for-your-next-data-science-project/",
      "description": "Three cases to use the Sphinx tool as a pro\nThe post Apply Sphinx’s Functionality to Create Documentation for Your Next Data Science Project appeared first on Towards Data Science.",
      "published_date": "2025-06-17T17:55:42+00:00",
      "collected_at": "2025-06-18T20:20:14.837163+00:00",
      "author": "Radmila Mandzhieva",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "23535b2f4318b27f71fcd30c6192cbee",
      "source_id": "pytorch_blog",
      "source": "Blog – PyTorch",
      "category": "Open Source",
      "title": "DeepNVMe: Affordable I/O scaling for Deep Learning Applications",
      "url": "https://pytorch.org/blog/deepnvme-affordable-i-o-scaling-for-deep-learning-applications/",
      "description": "Introduction We introduced DeepNVMe in summer 2024 as a suite of optimizations for tackling I/O bottlenecks in Deep Learning (DL). DeepNVMe delivers significant speedups for I/O bound DL workloads by leveraging storage...",
      "published_date": "2025-06-17T16:54:32+00:00",
      "collected_at": "2025-06-18T20:20:13.594118+00:00",
      "author": "Joe Mayer, Logan Adams, Olatunji Ruwase",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "a3f6cb6b9affea3b46a077d334d78320",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "From Bytes to Ideas: Language Modeling with Autoregressive U-Nets",
      "url": "https://arxiv.org/abs/2506.14761",
      "description": "Tokenization imposes a fixed granularity on the input text, freezing how a\nlanguage model operates on data and how far in the future it predicts. Byte\nPair Encoding (BPE) and similar schemes split text once, build a static\nvocabulary, and leave the model stuck with that choice. We relax this rigidity\nby introducing an autoregressive U-Net that learns to embed its own tokens as\nit trains. The network reads raw bytes, pools them into words, then pairs of\nwords, then up to 4 words, giving it a mult",
      "published_date": "2025-06-17T13:55:11+00:00",
      "collected_at": "2025-06-18T20:20:13.364666+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "993a414041e704e59c480619aad547c6",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Reasoning with Exploration: An Entropy Perspective",
      "url": "https://arxiv.org/abs/2506.14758",
      "description": "Balancing exploration and exploitation is a central goal in reinforcement\nlearning (RL). Despite recent advances in enhancing language model (LM)\nreasoning, most methods lean toward exploitation, and increasingly encounter\nperformance plateaus. In this work, we revisit entropy -- a signal of\nexploration in RL -- and examine its relationship to exploratory reasoning in\nLMs. Through empirical analysis, we uncover strong positive correlations\nbetween high-entropy regions and three types of explorat",
      "published_date": "2025-06-17T13:54:03+00:00",
      "collected_at": "2025-06-18T20:20:13.369389+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "b11c46691f29eefcb7e4cd645736a551",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning\n  for LLMs",
      "url": "https://arxiv.org/abs/2506.14731",
      "description": "We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model\noptimized via reinforcement learning (RL) to achieve efficient and robust\nreasoning capabilities. Built upon the publicly available Ling-lite model, a\n16.8 billion parameter model with 2.75 billion activated parameters, our\napproach matches the performance of state-of-the-art (SOTA) small-scale\nreasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench,\nGPQA-Diamond) while activating only one-third of the para",
      "published_date": "2025-06-17T13:12:34+00:00",
      "collected_at": "2025-06-18T20:20:13.368702+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "a51439b8f425ecd774ce46835ce68945",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time\n  Markers",
      "url": "https://arxiv.org/abs/2506.14702",
      "description": "One of the most profound challenges of modern machine learning is performing\nwell on the long-tail of rare and underrepresented features. Large\ngeneral-purpose models are trained for many tasks, but work best on\nhigh-frequency use cases. After training, it is hard to adapt a model to\nperform well on specific use cases underrepresented in the training corpus.\nRelying on prompt engineering or few-shot examples to maximize the output\nquality on a particular test case can be frustrating, as models c",
      "published_date": "2025-06-17T12:40:42+00:00",
      "collected_at": "2025-06-18T20:20:13.368938+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "2332630e127a833a3d176dd35801d0d3",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based\n  Mosquito Breeding Site Detection and Reasoning",
      "url": "https://arxiv.org/abs/2506.14629",
      "description": "Mosquito-borne diseases pose a major global health risk, requiring early\ndetection and proactive control of breeding sites to prevent outbreaks. In this\npaper, we present VisText-Mosquito, a multimodal dataset that integrates visual\nand textual data to support automated detection, segmentation, and reasoning\nfor mosquito breeding site analysis. The dataset includes 1,828 annotated\nimages for object detection, 142 images for water surface segmentation, and\nnatural language reasoning texts linked",
      "published_date": "2025-06-17T11:24:30+00:00",
      "collected_at": "2025-06-18T20:20:13.366365+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "b148d646bfb135a6466ca6f9950f0689",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Grad-CAM from Scratch with PyTorch Hooks",
      "url": "https://towardsdatascience.com/grad-cam-from-scratch-with-pytorch-hooks/",
      "description": "A hands-on look at an explainable AI (XAI) technique that helps reveal why a convolutional neural network (CNN) made a particular decision\nThe post Grad-CAM from Scratch with PyTorch Hooks appeared first on Towards Data Science.",
      "published_date": "2025-06-17T05:52:18+00:00",
      "collected_at": "2025-06-18T20:20:14.837351+00:00",
      "author": "Conor O'Sullivan",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "32d314415eaab25648b9084330e0895e",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Practical Starters’ Guide to Causal Structure Learning with Bayesian Methods in Python",
      "url": "https://towardsdatascience.com/a-practical-starters-guide-to-causal-structure-learning-with-bayesian-methods-in-python/",
      "description": "Learn Causal Structures and make inferences with Bayesian Methods: Python Tutorial\nThe post A Practical Starters’ Guide to Causal Structure Learning with Bayesian Methods in Python appeared first on Towards Data Science.",
      "published_date": "2025-06-17T00:45:46+00:00",
      "collected_at": "2025-06-18T20:20:14.837543+00:00",
      "author": "Erdogan Taskesen",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "3b18452ba89445f24ebc15f969f67868",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Let’s Analyze OpenAI’s Claims About ChatGPT Energy Use",
      "url": "https://towardsdatascience.com/lets-analyze-openais-claims-about-chatgpt-energy-use/",
      "description": "ChatGPT uses an average of 0.34 Wh per query, according to a blog post by Sam Altman. Does that figure hold up?\nThe post Let’s Analyze OpenAI’s Claims About ChatGPT Energy Use appeared first on Towards Data Science.",
      "published_date": "2025-06-16T19:31:58+00:00",
      "collected_at": "2025-06-18T20:20:14.837732+00:00",
      "author": "Kasper Groes Albin Ludvigsen",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "8d8888a67d52c0320ffd86cbc05ed4cb",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Regularisation: A Deep Dive into Theory, Implementation, and Practical Insights",
      "url": "https://towardsdatascience.com/regularisation-a-deep-dive-into-theory-implementation-and-practical-insights/",
      "description": "A detailed guide on controlling overfitting and increasing the stability of your models.\nThe post Regularisation: A Deep Dive into Theory, Implementation, and Practical Insights appeared first on Towards Data Science.",
      "published_date": "2025-06-16T19:16:38+00:00",
      "collected_at": "2025-06-18T20:20:14.837943+00:00",
      "author": "Sourav Mohile",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "14d12dcbf8fffaa0f6999e8d38d85738",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark\n  for Financial LLM Evaluation",
      "url": "https://arxiv.org/abs/2506.14028",
      "description": "Recent advances in large language models (LLMs) have accelerated progress in\nfinancial NLP and applications, yet existing benchmarks remain limited to\nmonolingual and unimodal settings, often over-relying on simple tasks and\nfailing to reflect the complexity of real-world financial communication. We\nintroduce MultiFinBen, the first multilingual and multimodal benchmark tailored\nto the global financial domain, evaluating LLMs across modalities (text,\nvision, audio) and linguistic settings (monoli",
      "published_date": "2025-06-16T18:01:49+00:00",
      "collected_at": "2025-06-18T20:20:13.365256+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "a0092c46510f51961c64ac45063c699d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Build an AI Agent to Explore Your Data Catalog with Natural Language",
      "url": "https://towardsdatascience.com/build-and-ai-agent-to-explore-your-data-catalog-with-natural-language/",
      "description": "Leverage LLMs to query your Databricks Data Catalog\nThe post Build an AI Agent to Explore Your Data Catalog with Natural Language appeared first on Towards Data Science.",
      "published_date": "2025-06-16T17:37:42+00:00",
      "collected_at": "2025-06-18T20:20:14.838128+00:00",
      "author": "Fabiana Clemente",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "38317db47248e6c73c6016a6ca7a648a",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "I Won $10,000 in a Machine Learning Competition — Here’s My Complete Strategy",
      "url": "https://towardsdatascience.com/i-won-10000-in-a-machine-learning-competition-heres-my-complete-strategy/",
      "description": "Complete guide to feature selection, threshold optimization, and neural network architecture for ML competitions\nThe post I Won $10,000 in a Machine Learning Competition — Here’s My Complete Strategy appeared first on Towards Data Science.",
      "published_date": "2025-06-16T17:12:24+00:00",
      "collected_at": "2025-06-18T20:20:14.838318+00:00",
      "author": "Claudia Ng",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "c3ad6fbaec8be7e9f6249a3c8589b100",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Agents, APIs, and the Next Layer of the Internet",
      "url": "https://towardsdatascience.com/agents-apis-and-the-next-layer-of-the-internet/",
      "description": "Part I: Shipping Containers for Thought Every so often a simple idea rewires everything. The shipping container didn’t just optimise logistics; it flattened the globe, collapsed time zones, and rewrote the economics of trade. In its geometric austerity was a quiet revolution: standardisation. Similarly, HTML and HTTP didn’t invent information exchange — any more than […]\nThe post Agents, APIs, and the Next Layer of the Internet appeared first on Towards Data Science.",
      "published_date": "2025-06-16T17:06:00+00:00",
      "collected_at": "2025-06-18T20:20:14.838518+00:00",
      "author": "Cooper Doyle",
      "source_priority": 3,
      "score": 92
    },
    {
      "id": "880b092cd7c4dc01d7189bcba2f0ebb1",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "DynaGuide: Steering Diffusion Polices with Active Dynamic Guidance",
      "url": "https://arxiv.org/abs/2506.13922",
      "description": "Deploying large, complex policies in the real world requires the ability to\nsteer them to fit the needs of a situation. Most common steering approaches,\nlike goal-conditioning, require training the robot policy with a distribution\nof test-time objectives in mind. To overcome this limitation, we present\nDynaGuide, a steering method for diffusion policies using guidance from an\nexternal dynamics model during the diffusion denoising process. DynaGuide\nseparates the dynamics model from the base poli",
      "published_date": "2025-06-16T15:00:54+00:00",
      "collected_at": "2025-06-18T20:20:13.366121+00:00",
      "author": "",
      "source_priority": 1,
      "score": 93
    },
    {
      "id": "173db796bf0f919992e56e5a4c54b256",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic\n  Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise\n  Pooled Representations",
      "url": "https://arxiv.org/abs/2506.13901",
      "description": "Alignment is no longer a luxury, it is a necessity. As large language models\n(LLMs) enter high-stakes domains like education, healthcare, governance, and\nlaw, their behavior must reliably reflect human-aligned values and safety\nconstraints. Yet current evaluations rely heavily on behavioral proxies such as\nrefusal rates, G-Eval scores, and toxicity classifiers, all of which have\ncritical blind spots. Aligned models are often vulnerable to jailbreaking,\nstochasticity of generation, and alignment",
      "published_date": "2025-06-16T14:22:28+00:00",
      "collected_at": "2025-06-18T20:20:13.368237+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "ab115f1edd481956f071444f4baf50fc",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "xbench: Tracking Agents Productivity Scaling with Profession-Aligned\n  Real-World Evaluations",
      "url": "https://arxiv.org/abs/2506.13651",
      "description": "We introduce xbench, a dynamic, profession-aligned evaluation suite designed\nto bridge the gap between AI agent capabilities and real-world productivity.\nWhile existing benchmarks often focus on isolated technical skills, they may\nnot accurately reflect the economic value agents deliver in professional\nsettings. To address this, xbench targets commercially significant domains with\nevaluation tasks defined by industry professionals. Our framework creates\nmetrics that strongly correlate with produ",
      "published_date": "2025-06-16T12:16:14+00:00",
      "collected_at": "2025-06-18T20:20:13.367758+00:00",
      "author": "",
      "source_priority": 1,
      "score": 93
    },
    {
      "id": "ef03811afc5a4f97dd25ca59758bbe5f",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Efficient Medical VIE via Reinforcement Learning",
      "url": "https://arxiv.org/abs/2506.13363",
      "description": "Visual Information Extraction (VIE) converts unstructured document images\ninto structured formats like JSON, critical for medical applications such as\nreport analysis and online consultations. Traditional methods rely on OCR and\nlanguage models, while end-to-end multimodal models offer direct JSON\ngeneration. However, domain-specific schemas and high annotation costs limit\ntheir effectiveness in medical VIE. We base our approach on the Reinforcement\nLearning with Verifiable Rewards (RLVR) framew",
      "published_date": "2025-06-16T07:10:25+00:00",
      "collected_at": "2025-06-18T20:20:13.369597+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "fc14198e20d0ee239eca712f77cdba82",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Scaling Test-time Compute for LLM Agents",
      "url": "https://arxiv.org/abs/2506.12928",
      "description": "Scaling test time compute has shown remarkable success in improving the\nreasoning abilities of large language models (LLMs). In this work, we conduct\nthe first systematic exploration of applying test-time scaling methods to\nlanguage agents and investigate the extent to which it improves their\neffectiveness. Specifically, we explore different test-time scaling strategies,\nincluding: (1) parallel sampling algorithms; (2) sequential revision\nstrategies; (3) verifiers and merging methods; (4)strateg",
      "published_date": "2025-06-15T13:59:47+00:00",
      "collected_at": "2025-06-18T20:20:13.368002+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "988084b4932f3c2f25b42addeac869e0",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Universal Jailbreak Suffixes Are Strong Attention Hijackers",
      "url": "https://arxiv.org/abs/2506.12880",
      "description": "We study suffix-based jailbreaksx2013a powerful family of attacks\nagainst large language models (LLMs) that optimize adversarial suffixes to\ncircumvent safety alignment. Focusing on the widely used foundational GCG\nattack (Zou et al., 2023), we observe that suffixes vary in efficacy: some\nmarkedly more universalx2013generalizing to many unseen harmful\ninstructionsx2013than others. We first show that GCG's\neffectiveness is driven by a shallow, critical mechanism, built on the\ninformation flow fro",
      "published_date": "2025-06-15T11:20:37+00:00",
      "collected_at": "2025-06-18T20:20:13.367015+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "0982c8bdf5f0c9191bd5ac8f4ecf7bf5",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Stop Building AI Platforms",
      "url": "https://towardsdatascience.com/stop-building-ai-platforms/",
      "description": "When small and medium companies achieve success in building Data and ML platforms, building AI platforms is now profoundly challenging\nThe post Stop Building AI Platforms appeared first on Towards Data Science.",
      "published_date": "2025-06-14T01:26:49+00:00",
      "collected_at": "2025-06-18T20:20:14.838882+00:00",
      "author": "Ming Gao",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "58f37280e0df15f573bc141bb368f7e0",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "What If I had AI in 2018: Rent the Runway Fulfillment Center Optimization",
      "url": "https://towardsdatascience.com/what-if-i-had-ai-in-2018-rent-the-runway-fulfillment-center-optimization/",
      "description": "An LLM in 2018 would not have trivialized a complex project, although it could have enhanced the final solution\nThe post What If I had AI in 2018: Rent the Runway Fulfillment Center Optimization appeared first on Towards Data Science.",
      "published_date": "2025-06-13T23:03:03+00:00",
      "collected_at": "2025-06-18T20:20:14.839073+00:00",
      "author": "Hugo Ducruc",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "d3eda90a1df9e9e47bb4a7427f6c44b5",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "CMI-Bench: A Comprehensive Benchmark for Evaluating Music Instruction\n  Following",
      "url": "https://arxiv.org/abs/2506.12285",
      "description": "Recent advances in audio-text large language models (LLMs) have opened new\npossibilities for music understanding and generation. However, existing\nbenchmarks are limited in scope, often relying on simplified tasks or\nmulti-choice evaluations that fail to reflect the complexity of real-world\nmusic analysis. We reinterpret a broad range of traditional MIR annotations as\ninstruction-following formats and introduce CMI-Bench, a comprehensive music\ninstruction following benchmark designed to evaluate",
      "published_date": "2025-06-13T20:18:44+00:00",
      "collected_at": "2025-06-18T20:20:13.365545+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "08e4357cebd144a10ee62a390d9691a5",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "AI Is Not a Black Box (Relatively Speaking)",
      "url": "https://towardsdatascience.com/ai-is-not-a-black-box/",
      "description": "Compared to the opacity around human intelligence, AI is more transparent in some very tangible ways.\nThe post AI Is Not a Black Box (Relatively Speaking) appeared first on Towards Data Science.",
      "published_date": "2025-06-13T20:02:51+00:00",
      "collected_at": "2025-06-18T20:20:14.839254+00:00",
      "author": "Piotr (Peter) Mardziel",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "a47ee4e7d65a00ac2f3bffd11bc261a4",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How AI Agents “Talk” to Each Other",
      "url": "https://towardsdatascience.com/how-ai-agents-talk-to-each-other/",
      "description": "Minimize chaos and maintain inter-agent harmony in your projects\nThe post How AI Agents “Talk” to Each Other appeared first on Towards Data Science.",
      "published_date": "2025-06-13T19:21:14+00:00",
      "collected_at": "2025-06-18T20:20:14.839450+00:00",
      "author": "TDS Editors",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "60c1fe34ea4d768996bae1b32a454c16",
      "source_id": "pytorch_blog",
      "source": "Blog – PyTorch",
      "category": "Open Source",
      "title": "ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization",
      "url": "https://pytorch.org/blog/paretoq-scaling-laws-in-extremely-low-bit-llm-quantization/",
      "description": "The field of large language models is shifting toward lower-precision computation. This shift necessitates a rethinking of scaling laws to account for the effects of quantization on resulting quantized model...",
      "published_date": "2025-06-13T18:43:38+00:00",
      "collected_at": "2025-06-18T20:20:13.594201+00:00",
      "author": "Zechun Liu, Changsheng Zhao, Hanxian Huang, Sijia Chen, Jing Zhang, Andrew Or, Jiawei Zhao, Scott Roy, Lisa Jin, Yunyang Xiong, Yangyang Shi, Lin Xiao, Yuandong Tian, Bilge Soran, Raghuraman Krishnamoorthi, Tijmen Blankevoort, Vikas Chandra (Meta)",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "212bcd0e6d9f3fde4b3995133b4675df",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction",
      "url": "https://arxiv.org/abs/2506.12015",
      "description": "Open-source foundation models have seen rapid adoption and development,\nenabling powerful general-purpose capabilities across diverse domains. However,\nfine-tuning large foundation models for domain-specific or personalized tasks\nremains prohibitively expensive for most users due to the significant memory\noverhead beyond that of inference. We introduce EMLoC, an Emulator-based\nMemory-efficient fine-tuning framework with LoRA Correction, which enables\nmodel fine-tuning within the same memory budg",
      "published_date": "2025-06-13T13:59:58+00:00",
      "collected_at": "2025-06-18T20:20:13.367528+00:00",
      "author": "",
      "source_priority": 1,
      "score": 89
    },
    {
      "id": "2d83a9cb9a328057c618264033ae1dbe",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Connecting the Dots for Better Movie Recommendations",
      "url": "https://towardsdatascience.com/connecting-the-dots-for-better-movie-recommendations/",
      "description": "Connecting the Dots for Better Movie Recommendations: Lightweight graph RAG on Rotten Tomatoes movie reviews\nThe post Connecting the Dots for Better Movie Recommendations appeared first on Towards Data Science.",
      "published_date": "2025-06-13T00:27:55+00:00",
      "collected_at": "2025-06-18T20:20:14.839629+00:00",
      "author": "Brian Godsey",
      "source_priority": 3,
      "score": 88
    }
  ],
  "updated": "2025-06-18T20:20:54.512600"
}