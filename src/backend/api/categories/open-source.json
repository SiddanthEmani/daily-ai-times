{
  "category": "Open Source",
  "count": 40,
  "articles": [
    {
      "id": "8647cd9cdb434e35eec9fb9d5d10b3c7",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Audio Spectrogram Transformers Beyond the Lab",
      "url": "https://towardsdatascience.com/audio-spectrogram-transformers-beyond-the-lab/",
      "description": "A recipe for building a portable soundscape monitoring app with AudioMoth, Raspberry Pi, and a decent dose of deep learning.\nThe post Audio Spectrogram Transformers Beyond the Lab appeared first on Towards Data Science.",
      "published_date": "2025-06-10T23:47:29+00:00",
      "collected_at": "2025-06-11T08:22:32.888782+00:00",
      "author": "Maciej Adamiak",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "670434083c4a15bec64ebb9e2cdcc44c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Automate Models Training: An MLOps Pipeline with Tekton and Buildpacks",
      "url": "https://towardsdatascience.com/automate-models-training-an-mlops-pipeline-with-tekton-and-buildpacks/",
      "description": "A step-by-step guide to containerizing and orchestrating an ML training workflow without the Dockerfile headache, using a lightweight GPT-2 example.\nThe post Automate Models Training: An MLOps Pipeline with Tekton and Buildpacks appeared first on Towards Data Science.",
      "published_date": "2025-06-10T23:37:18+00:00",
      "collected_at": "2025-06-11T08:22:32.888996+00:00",
      "author": "Sylvain Kalache",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "14d58c32a594dab10314ce70e770deaf",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "10,000x Faster Bayesian Inference: Multi-GPU SVI vs. Traditional MCMC",
      "url": "https://towardsdatascience.com/10000x-faster-bayesian-inference-multi-gpu-svi-vs-traditional-mcmc/",
      "description": "Using GPU acceleration to speed up Bayesian Inference from months to minutes... \nThe post 10,000x Faster Bayesian Inference: Multi-GPU SVI vs. Traditional MCMC appeared first on Towards Data Science.",
      "published_date": "2025-06-10T23:29:05+00:00",
      "collected_at": "2025-06-11T08:22:32.889197+00:00",
      "author": "Derek Tran",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "50915c04bf618d568192a3eb44ce6fec",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Applications of Density Estimation to Legal Theory",
      "url": "https://towardsdatascience.com/applications-of-density-estimation-to-legal-theory/",
      "description": "A brief analysis using density estimation to compare the two-verdict and three-verdict systems.\nThe post Applications of Density Estimation to Legal Theory appeared first on Towards Data Science.",
      "published_date": "2025-06-10T16:36:24+00:00",
      "collected_at": "2025-06-11T08:22:32.889394+00:00",
      "author": "Jimin Kang",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "53637d24fd864403f01665e3ce2fa624",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Autoregressive Semantic Visual Reconstruction Helps VLMs Understand\n  Better",
      "url": "https://arxiv.org/abs/2506.09040",
      "description": "Typical large vision-language models (LVLMs) apply autoregressive supervision\nsolely to textual sequences, without fully incorporating the visual modality\ninto the learning process. This results in three key limitations: (1) an\ninability to utilize images without accompanying captions, (2) the risk that\ncaptions omit critical visual details, and (3) the challenge that certain\nvision-centric content cannot be adequately conveyed through text. As a result,\ncurrent LVLMs often prioritize vision-to-",
      "published_date": "2025-06-10T13:57:50+00:00",
      "collected_at": "2025-06-11T08:22:31.273314+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "168871f439590541d471d763b4f0f88d",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for\n  Parameter-Efficient Video-Text Retrieval",
      "url": "https://arxiv.org/abs/2506.08887",
      "description": "The parameter-efficient adaptation of the image-text pretraining model CLIP\nfor video-text retrieval is a prominent area of research. While CLIP is focused\non image-level vision-language matching, video-text retrieval demands\ncomprehensive understanding at the video level. Three key discrepancies emerge\nin the transfer from image-level to video-level: vision, language, and\nalignment. However, existing methods mainly focus on vision while neglecting\nlanguage and alignment. In this paper, we propo",
      "published_date": "2025-06-10T11:16:40+00:00",
      "collected_at": "2025-06-11T08:22:31.275834+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "2cba20a73aaee2108868ab012d464b99",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Mastering SQL Window Functions",
      "url": "https://towardsdatascience.com/mastering-sql-window-functions/",
      "description": "Understand how to use Window Functions to perform calculations without losing\u00a0details\nThe post Mastering SQL Window Functions appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:36:15+00:00",
      "collected_at": "2025-06-11T08:22:32.889609+00:00",
      "author": "Eugenia Anello",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "f85347fb0559744e9a6053beb02e544f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Exploratory Data Analysis: Gamma Spectroscopy in Python",
      "url": "https://towardsdatascience.com/exploratory-data-analysis-gamma-spectroscopy-in-python/",
      "description": "Let\u2019s observe the matter on the atomic level\nThe post Exploratory Data Analysis: Gamma Spectroscopy in Python appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:27:05+00:00",
      "collected_at": "2025-06-11T08:22:32.889816+00:00",
      "author": "Dmitrii Eliuseev",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "b5e500a2d2ad993b7c2a8d260dbc2196",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Bird\u2019s-Eye View of Linear Algebra: Measure of a Map \u2014 Determinants",
      "url": "https://towardsdatascience.com/a-birds-eye-view-of-linear-algebra-measure-of-a-map-determinants/",
      "description": "We roll up our sleeves and start to deal with matrices\nThe post A Bird\u2019s-Eye View of Linear Algebra: Measure of a Map \u2014 Determinants appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:00:27+00:00",
      "collected_at": "2025-06-11T08:22:32.890016+00:00",
      "author": "Rohit Pandey",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "8974cbf315fc128cbdcbf27fffa994ba",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How to Transition From Data Analyst to Data Scientist",
      "url": "https://towardsdatascience.com/how-to-transition-from-data-analyst-to-data-scientist/",
      "description": "Playbook on how data analysts can become data scientists\nThe post How to Transition From Data Analyst to Data Scientist appeared first on Towards Data Science.",
      "published_date": "2025-06-09T23:09:55+00:00",
      "collected_at": "2025-06-11T08:22:32.890212+00:00",
      "author": "Egor Howell",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "5bb2aa15fbc6f8e0fd06eba34a4606b2",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Trying to Stay Sane in the Age of\u00a0AI",
      "url": "https://towardsdatascience.com/trying-to-stay-sane-in-the-age-of-ai/",
      "description": "A machine learning engineer\u2019s quiet way of not losing her mind\nThe post Trying to Stay Sane in the Age of\u00a0AI appeared first on Towards Data Science.",
      "published_date": "2025-06-09T22:50:40+00:00",
      "collected_at": "2025-06-11T08:22:32.890408+00:00",
      "author": "Amy Ma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "3c1a526d08896a66ec4498f5f2f20bf0",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Self Forcing: Bridging the Train-Test Gap in Autoregressive Video\n  Diffusion",
      "url": "https://arxiv.org/abs/2506.08009",
      "description": "We introduce Self Forcing, a novel training paradigm for autoregressive video\ndiffusion models. It addresses the longstanding issue of exposure bias, where\nmodels trained on ground-truth context must generate sequences conditioned on\ntheir own imperfect outputs during inference. Unlike prior methods that denoise\nfuture frames based on ground-truth context frames, Self Forcing conditions\neach frame's generation on previously self-generated outputs by performing\nautoregressive rollout with key-val",
      "published_date": "2025-06-09T13:59:55+00:00",
      "collected_at": "2025-06-11T08:22:31.274134+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "e8d065eae704eddc032550cdcaacc943",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Dynamic View Synthesis as an Inverse Problem",
      "url": "https://arxiv.org/abs/2506.08004",
      "description": "In this work, we address dynamic view synthesis from monocular videos as an\ninverse problem in a training-free setting. By redesigning the noise\ninitialization phase of a pre-trained video diffusion model, we enable\nhigh-fidelity dynamic view synthesis without any weight updates or auxiliary\nmodules. We begin by identifying a fundamental obstacle to deterministic\ninversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and\nresolve it by introducing a novel noise representation,",
      "published_date": "2025-06-09T13:59:47+00:00",
      "collected_at": "2025-06-11T08:22:31.277154+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "572b61324a1c42d3472e013ab0503e2c",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Aligning Text, Images, and 3D Structure Token-by-Token",
      "url": "https://arxiv.org/abs/2506.08002",
      "description": "Creating machines capable of understanding the world in 3D is essential in\nassisting designers that build and edit 3D environments and robots navigating\nand interacting within a three-dimensional space. Inspired by advances in\nlanguage and image modeling, we investigate the potential of autoregressive\nmodels for a new modality: structured 3D scenes. To this end, we propose a\nunified LLM framework that aligns language, images, and 3D scenes and provide a\ndetailed ''cookbook'' outlining critical d",
      "published_date": "2025-06-09T13:59:37+00:00",
      "collected_at": "2025-06-11T08:22:31.275361+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "6122a3620b58a26327ff5ef77e632285",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "\u03c4^2-Bench: Evaluating Conversational Agents in a Dual-Control\n  Environment",
      "url": "https://arxiv.org/abs/2506.07982",
      "description": "Existing benchmarks for conversational AI agents simulate single-control\nenvironments, where only the AI agent can use tools to interact with the world,\nwhile the user remains a passive information provider. This differs from\nreal-world scenarios like technical support, where users need to actively\nparticipate in modifying the state of the (shared) world. In order to address\nthis gap, we introduce tau^2-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec",
      "published_date": "2025-06-09T13:52:18+00:00",
      "collected_at": "2025-06-11T08:22:31.278102+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "53f2baf5bd8a80660518721e8ba69107",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural\n  Compressor",
      "url": "https://arxiv.org/abs/2506.07932",
      "description": "We propose Squeeze3D, a novel framework that leverages implicit prior\nknowledge learnt by existing pre-trained 3D generative models to compress 3D\ndata at extremely high compression ratios. Our approach bridges the latent\nspaces between a pre-trained encoder and a pre-trained generation model through\ntrainable mapping networks. Any 3D model represented as a mesh, point cloud, or\na radiance field is first encoded by the pre-trained encoder and then\ntransformed (i.e. compressed) into a highly comp",
      "published_date": "2025-06-09T12:52:10+00:00",
      "collected_at": "2025-06-11T08:22:31.275132+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "00b0e43eca89e727ef847f91d2727400",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Solving Inequality Proofs with Large Language Models",
      "url": "https://arxiv.org/abs/2506.07927",
      "description": "Inequality proving, crucial across diverse scientific and mathematical\nfields, tests advanced reasoning skills such as discovering tight bounds and\nstrategic theorem application. This makes it a distinct, demanding frontier for\nlarge language models (LLMs), offering insights beyond general mathematical\nproblem-solving. Progress in this area is hampered by existing datasets that\nare often scarce, synthetic, or rigidly formal. We address this by proposing an\ninformal yet verifiable task formulatio",
      "published_date": "2025-06-09T12:43:38+00:00",
      "collected_at": "2025-06-11T08:22:31.274386+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "649114649cbcb5cae6329b76e8cdb1e7",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional\n  Autonomous Agent Systems",
      "url": "https://arxiv.org/abs/2506.07564",
      "description": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-graine",
      "published_date": "2025-06-09T05:04:37+00:00",
      "collected_at": "2025-06-11T08:22:31.277687+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "9112bb07191d7f45c7ebe3953c8403e5",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Frame Guidance: Training-Free Guidance for Frame-Level Control in Video\n  Diffusion Models",
      "url": "https://arxiv.org/abs/2506.07177",
      "description": "Advancements in diffusion models have significantly improved video quality,\ndirecting attention to fine-grained controllability. However, many existing\nmethods depend on fine-tuning large-scale video models for specific tasks,\nwhich becomes increasingly impractical as model sizes continue to grow. In this\nwork, we present Frame Guidance, a training-free guidance for controllable\nvideo generation based on frame-level signals, such as keyframes, style\nreference images, sketches, or depth maps. For",
      "published_date": "2025-06-08T10:54:41+00:00",
      "collected_at": "2025-06-11T08:22:31.274879+00:00",
      "author": "",
      "source_priority": 1,
      "score": 92
    },
    {
      "id": "b537c66f6d11139c7cfa1129a574c64c",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Mathesis: Towards Formal Theorem Proving from Natural Languages",
      "url": "https://arxiv.org/abs/2506.07047",
      "description": "Recent advances in large language models show strong promise for formal\nreasoning. However, most LLM-based theorem provers have long been constrained\nby the need for expert-written formal statements as inputs, limiting their\napplicability to real-world problems expressed in natural language. We tackle\nthis gap with Mathesis, the first end-to-end theorem proving pipeline\nprocessing informal problem statements. It contributes Mathesis-Autoformalizer,\nthe first autoformalizer using reinforcement le",
      "published_date": "2025-06-08T05:04:14+00:00",
      "collected_at": "2025-06-11T08:22:31.273600+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "bb6f35ae695459147e05c3942a6c4762",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Geopolitical biases in LLMs: what are the \"good\" and the \"bad\" countries\n  according to contemporary language models",
      "url": "https://arxiv.org/abs/2506.06751",
      "description": "This paper evaluates geopolitical biases in LLMs with respect to various\ncountries though an analysis of their interpretation of historical events with\nconflicting national perspectives (USA, UK, USSR, and China). We introduce a\nnovel dataset with neutral event descriptions and contrasting viewpoints from\ndifferent countries. Our findings show significant geopolitical biases, with\nmodels favoring specific national narratives. Additionally, simple debiasing\nprompts had a limited effect in reducin",
      "published_date": "2025-06-07T06:45:17+00:00",
      "collected_at": "2025-06-11T08:22:31.274640+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "0824d42f02602fe5c6694dd04b455c40",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit",
      "url": "https://arxiv.org/abs/2506.06607",
      "description": "We present a training-free method to transplant tokenizers in pretrained\nlarge language models (LLMs) by reconstructing unseen token embeddings via\nOrthogonal Matching Pursuit (OMP). Specifically, we approximate each\nout-of-vocabulary token as a sparse linear combination of shared tokens, in two\nphases: first, compute each new token's representation in the donor embedding\nspace with a small dictionary of shared anchor tokens, then transfer these same\nsparse coefficients back into the base model'",
      "published_date": "2025-06-06T20:51:27+00:00",
      "collected_at": "2025-06-11T08:22:31.276594+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "ba0a1d0ca488df04266d6f48441d1523",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "HuggingFace Safetensors Support in PyTorch Distributed Checkpointing",
      "url": "https://pytorch.org/blog/huggingface-safetensors-support-in-pytorch-distributed-checkpointing/",
      "description": "Summary\u00a0 PyTorch Distributed Checkpointing (DCP) is making investments into addressing the interoperability blockers to ensure that popular formats, like HuggingFace safetensors, can work well with PyTorch\u2019s ecosystem. Since HuggingFace has...",
      "published_date": "2025-06-06T19:17:46+00:00",
      "collected_at": "2025-06-11T08:22:31.474311+00:00",
      "author": "Ankita George, Saurabh Mishra, Joe Cummings, Philip Bontrager, Daulet Askarov, Teja Rao, Chien-Chin Huang, Ela Krepska, Jafar Taghiyar",
      "source_priority": 2,
      "score": 91
    },
    {
      "id": "f2e2ef796ae85073f0397c059bcd40ea",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value",
      "url": "https://towardsdatascience.com/not-everything-needs-automation-5-practical-ai-agents-that-deliver-enterprise-value/",
      "description": "What actually works with AI agents inside enterprise organizations?\nThe post Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:54:12+00:00",
      "collected_at": "2025-06-11T08:22:32.890622+00:00",
      "author": "Weiwei Hu",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "3d5ee6adb52013963931f8bccef6033c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling.",
      "url": "https://towardsdatascience.com/prescriptive-modeling-unpacked-a-complete-guide-to-intervention-with-bayesian-modeling/",
      "description": "Learn how to move beyond prediction and actively make intervention through prescriptive modeling. This in-depth guide walks you through Bayesian approaches to system intervention, with practical examples in predictive maintenance.\nThe post Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling. appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:23:32+00:00",
      "collected_at": "2025-06-11T08:22:32.890819+00:00",
      "author": "Erdogan Taskesen",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "1baeabdb760d5d46d8825a522a214e3e",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How I Automated My Machine Learning Workflow with Just 10 Lines of\u00a0Python",
      "url": "https://towardsdatascience.com/how-i-automated-my-machine-learning-workflow-with-just-10-lines-of-python/",
      "description": "Use LazyPredict and PyCaret to skip the grunt work and jump straight to performance.\nThe post How I Automated My Machine Learning Workflow with Just 10 Lines of\u00a0Python appeared first on Towards Data Science.",
      "published_date": "2025-06-06T13:11:46+00:00",
      "collected_at": "2025-06-11T08:22:32.891015+00:00",
      "author": "Himanshu Sharma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "189d9a77fa5b000dafc2b8d8a009696c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "The Role of Luck in Sports: Can We Measure It?",
      "url": "https://towardsdatascience.com/the-role-of-luck-in-sports-can-we-measure-it/",
      "description": "From last-minute goals to coin tosses: How much does randomness influence the outcomes of games?\nThe post The Role of Luck in Sports: Can We Measure It? appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:56:13+00:00",
      "collected_at": "2025-06-11T08:22:32.891211+00:00",
      "author": "Pol Marin",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "13273eb8ef106c023f296d5889a2003f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Why AI Projects Fail",
      "url": "https://towardsdatascience.com/why-ai-projects-fail/",
      "description": "No one agrees on the exact number, but estimates say anywhere from 50% to 80% of AI projects end in failure.\nThe post Why AI Projects Fail appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:49:02+00:00",
      "collected_at": "2025-06-11T08:22:32.891404+00:00",
      "author": "Ivo Bernardo",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "cc9ddd43ece4c0107e3dc3a3caa42148",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "5 Crucial Tweaks That Will Make Your Charts Accessible to People with Visual Impairments",
      "url": "https://towardsdatascience.com/5-crucial-tweaks-that-will-make-your-charts-accessible-to-people-with-visual-impairments/",
      "description": "More than 350 million people are colorblind - Make sure they can read your visualizations.\nThe post 5 Crucial Tweaks That Will Make Your Charts Accessible to People with Visual Impairments appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:39:46+00:00",
      "collected_at": "2025-06-11T08:22:32.891614+00:00",
      "author": "Dario Rade\u010di\u0107",
      "source_priority": 3,
      "score": 89
    },
    {
      "id": "5f0c1c6a778613d59a8e6b597a3b7d0c",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient\n  Fine-Tuning of Large Language Models",
      "url": "https://arxiv.org/abs/2506.05928",
      "description": "Recent studies integrate Low-Rank Adaptation (LoRA) and Mixture-of-Experts\n(MoE) to further enhance the performance of parameter-efficient fine-tuning\n(PEFT) methods in Large Language Model (LLM) applications. Existing methods\nemploy homogeneous MoE-LoRA architectures composed of LoRA experts with\neither similar or identical structures and capacities. However, these\napproaches often suffer from representation collapse and expert load imbalance,\nwhich negatively impact the potential of LLMs. To a",
      "published_date": "2025-06-06T05:54:19+00:00",
      "collected_at": "2025-06-11T08:22:31.275603+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "6672a234489ba529ecfaef5d7db8e8e1",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "RKEFino1: A Regulation Knowledge-Enhanced Large Language Model",
      "url": "https://arxiv.org/abs/2506.05700",
      "description": "Recent advances in large language models (LLMs) hold great promise for\nfinancial applications but introduce critical accuracy and compliance\nchallenges in Digital Regulatory Reporting (DRR). To address these issues, we\npropose RKEFino1, a regulation knowledge-enhanced financial reasoning model\nbuilt upon Fino1, fine-tuned with domain knowledge from XBRL, CDM, and MOF. We\nformulate two QA tasks-knowledge-based and mathematical reasoning-and introduce\na novel Numerical NER task covering financial",
      "published_date": "2025-06-05T23:02:52+00:00",
      "collected_at": "2025-06-11T08:22:31.276342+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "d7545a1a922f41c500ffbeb3b257c62d",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Introducing the PyTorch Ecosystem Working Group and Project Spotlights",
      "url": "https://pytorch.org/blog/introducing-the-pytorch-ecosystem-working-group-and-project-spotlights/",
      "description": "The PyTorch Ecosystem goes back several years, with some of its earliest projects like Hugging Face, Fast.ai, and PyTorch Lightning going on to grow incredible communities of their own. The...",
      "published_date": "2025-06-05T19:57:09+00:00",
      "collected_at": "2025-06-11T08:22:31.474392+00:00",
      "author": "PyTorch Ecosystem Working Group",
      "source_priority": 2,
      "score": 90
    },
    {
      "id": "d0d95d1257b1a6fde6db88efe050f177",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Get Ready for Your Next Career Move",
      "url": "https://towardsdatascience.com/get-ready-for-your-next-career-move/",
      "description": "Are you planning to switch roles in the near future? On the lookout for your first data science or machine learning position? Regardless of your\u00a0career stage, change and growth are likely on your mind \u2014 and we\u2019re here to help. At the core of this week\u2019s Variable are articles that center the skills and knowledge [\u2026]\nThe post Get Ready for Your Next Career Move appeared first on Towards Data Science.",
      "published_date": "2025-06-05T12:30:00+00:00",
      "collected_at": "2025-06-11T08:22:32.891984+00:00",
      "author": "TDS Editors",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "525cd1ab29c12b2ff6c83820fc5de36c",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG",
      "url": "https://arxiv.org/abs/2506.05167",
      "description": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain\nQuestion Answering (ODQA) by leveraging external documents through\nRetrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer\ncontext, context compression is necessary. However, prior compression methods\ndo not focus on filtering out non-evidential information, which limit the\nperformance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or\nECoRAG framework. ECoRAG improves LLM performance by c",
      "published_date": "2025-06-05T11:43:49+00:00",
      "collected_at": "2025-06-11T08:22:31.276060+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "3fd2c9f9d684bc96e1e7da41814f0459",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning",
      "url": "https://arxiv.org/abs/2506.04651",
      "description": "Recent advances in LLMs have enabled their use as autonomous agents across a\nrange of tasks, yet they continue to struggle with formulating and adhering to\ncoherent long-term strategies. In this paper, we investigate whether LLM agents\ncan self-improve when placed in environments that explicitly challenge their\nstrategic planning abilities. Using the board game Settlers of Catan, accessed\nthrough the open-source Catanatron framework, we benchmark a progression of\nLLM-based agents, from a simple",
      "published_date": "2025-06-05T01:45:24+00:00",
      "collected_at": "2025-06-11T08:22:31.277896+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "24a66fab5b7a0290c75b0b2b8ff9bced",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Look Before You Leap: A GUI-Critic-R1 Model for Pre-Operative Error\n  Diagnosis in GUI Automation",
      "url": "https://arxiv.org/abs/2506.04614",
      "description": "In recent years, Multimodal Large Language Models (MLLMs) have been\nextensively utilized for multimodal reasoning tasks, including Graphical User\nInterface (GUI) automation. Unlike general offline multimodal tasks, GUI\nautomation is executed in online interactive environments, necessitating\nstep-by-step decision-making based on real-time status of the environment. This\ntask has a lower tolerance for decision-making errors at each step, as any\nmistakes may cumulatively disrupt the process and pot",
      "published_date": "2025-06-05T00:12:36+00:00",
      "collected_at": "2025-06-11T08:22:31.273873+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "07911bf4783ae8c988df398024f0a29d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "The Journey from Jupyter to Programmer: A Quick-Start Guide",
      "url": "https://towardsdatascience.com/the-journey-from-jupyter-to-programmer-a-quick-start-guide/",
      "description": "Explore the real benefits of ditching the notebook\nThe post The Journey from Jupyter to Programmer: A Quick-Start Guide appeared first on Towards Data Science.",
      "published_date": "2025-06-04T23:22:34+00:00",
      "collected_at": "2025-06-11T08:22:32.892178+00:00",
      "author": "Lucy Dickinson",
      "source_priority": 3,
      "score": 87
    },
    {
      "id": "6a6aa23d24a1e4c8a12c3043c7f51740",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Building a Modern Dashboard with Python and Gradio",
      "url": "https://towardsdatascience.com/building-a-modern-dashboard-with-python-and-gradio/",
      "description": "Data insights made simple\nThe post Building a Modern Dashboard with Python and Gradio appeared first on Towards Data Science.",
      "published_date": "2025-06-04T22:33:11+00:00",
      "collected_at": "2025-06-11T08:22:32.892364+00:00",
      "author": "Thomas Reid",
      "source_priority": 3,
      "score": 87
    },
    {
      "id": "b1b6d73dcf6dbf65fecf7f79e99c8711",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Open Source AI is Transforming the Economy\u2014Here\u2019s What the Data Shows",
      "url": "https://pytorch.org/blog/open-source-ai-is-transforming-the-economy-heres-what-the-data-shows/",
      "description": "Blog cross-posted on the Linux Foundation blog.\nAs we approach the midpoint of 2025, the potential of AI to transform businesses, economies, and industries is not only widely anticipated and nearly universal but also well documented. In a commissioned project by Meta, LF Research set out to capture existing evidence on this topic, with the specific aim of understanding how open source is playing a role in this transformation.\nIn its latest publication,\u00a0The Economic and Workforce Impacts o",
      "published_date": "2025-06-04T19:31:06+00:00",
      "collected_at": "2025-06-11T08:22:31.476888+00:00",
      "author": "Frank Nagle, Assistant Professor in the Strategy Unit at Harvard Business School and Advising Chief Economist at the Linux Foundation",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "6e80dcb1096a6d87c7d198fb883f6e73",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Build Responsible AI Products with your own Yellow Teaming LLM",
      "url": "https://pytorch.org/blog/build-responsible-ai-products-with-your-own-yellow-teaming-llm/",
      "description": "The tools we use to build AI are evolving fast, with PyTorch at the heart of many advances. But unless we evolve the way we approach building AI systems, we...",
      "published_date": "2025-06-04T14:37:23+00:00",
      "collected_at": "2025-06-11T08:22:31.476972+00:00",
      "author": "Zach Lasiuk, Principal Solutions Designer, Arm",
      "source_priority": 2,
      "score": 100
    }
  ]
}