{
  "category": "Open Source",
  "count": 42,
  "articles": [
    {
      "id": "2cba20a73aaee2108868ab012d464b99",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Mastering SQL Window Functions",
      "url": "https://towardsdatascience.com/mastering-sql-window-functions/",
      "description": "Understand how to use Window Functions to perform calculations without losing\u00a0details\nThe post Mastering SQL Window Functions appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:36:15+00:00",
      "collected_at": "2025-06-10T08:23:12.528647+00:00",
      "author": "Eugenia Anello",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "f85347fb0559744e9a6053beb02e544f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Exploratory Data Analysis: Gamma Spectroscopy in Python",
      "url": "https://towardsdatascience.com/exploratory-data-analysis-gamma-spectroscopy-in-python/",
      "description": "Let\u2019s observe the matter on the atomic level\nThe post Exploratory Data Analysis: Gamma Spectroscopy in Python appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:27:05+00:00",
      "collected_at": "2025-06-10T08:23:12.528883+00:00",
      "author": "Dmitrii Eliuseev",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "b5e500a2d2ad993b7c2a8d260dbc2196",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Bird\u2019s-Eye View of Linear Algebra: Measure of a Map \u2014 Determinants",
      "url": "https://towardsdatascience.com/a-birds-eye-view-of-linear-algebra-measure-of-a-map-determinants/",
      "description": "We roll up our sleeves and start to deal with matrices\nThe post A Bird\u2019s-Eye View of Linear Algebra: Measure of a Map \u2014 Determinants appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:00:27+00:00",
      "collected_at": "2025-06-10T08:23:12.529089+00:00",
      "author": "Rohit Pandey",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "8974cbf315fc128cbdcbf27fffa994ba",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How to Transition From Data Analyst to Data Scientist",
      "url": "https://towardsdatascience.com/how-to-transition-from-data-analyst-to-data-scientist/",
      "description": "Playbook on how data analysts can become data scientists\nThe post How to Transition From Data Analyst to Data Scientist appeared first on Towards Data Science.",
      "published_date": "2025-06-09T23:09:55+00:00",
      "collected_at": "2025-06-10T08:23:12.529292+00:00",
      "author": "Egor Howell",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "5bb2aa15fbc6f8e0fd06eba34a4606b2",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Trying to Stay Sane in the Age of\u00a0AI",
      "url": "https://towardsdatascience.com/trying-to-stay-sane-in-the-age-of-ai/",
      "description": "A machine learning engineer\u2019s quiet way of not losing her mind\nThe post Trying to Stay Sane in the Age of\u00a0AI appeared first on Towards Data Science.",
      "published_date": "2025-06-09T22:50:40+00:00",
      "collected_at": "2025-06-10T08:23:12.529493+00:00",
      "author": "Amy Ma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "74970be4a850eedb02717190d63dbed3",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Vision Transformers Don't Need Trained Registers",
      "url": "https://arxiv.org/abs/2506.08010",
      "description": "We investigate the mechanism underlying a previously identified phenomenon in\nVision Transformers -- the emergence of high-norm tokens that lead to noisy\nattention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a\nsparse set of neurons is responsible for concentrating high-norm activations on\noutlier tokens, leading to irregular attention patterns and degrading\ndownstream visual processing. While the existing solution for removing these\noutliers involves retraining models from scr",
      "published_date": "2025-06-09T13:59:57+00:00",
      "collected_at": "2025-06-10T08:23:10.843129+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "2177e4aa7a669ab0c6f1b8925c822a14",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Dreamland: Controllable World Creation with Simulator and Generative\n  Models",
      "url": "https://arxiv.org/abs/2506.08006",
      "description": "Large-scale video generative models can synthesize diverse and realistic\nvisual content for dynamic world creation, but they often lack element-wise\ncontrollability, hindering their use in editing scenes and training embodied AI\nagents. We propose Dreamland, a hybrid world generation framework combining the\ngranular control of a physics-based simulator and the photorealistic content\noutput of large-scale pretrained generative models. In particular, we design a\nlayered world abstraction that enco",
      "published_date": "2025-06-09T13:59:52+00:00",
      "collected_at": "2025-06-10T08:23:10.844958+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "62919ab2d8a7b7284fd9caad39b9c5c1",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers",
      "url": "https://arxiv.org/abs/2506.07986",
      "description": "Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress\nin text-driven visual generation. However, even state-of-the-art MM-DiT models\nlike FLUX struggle with achieving precise alignment between text prompts and\ngenerated content. We identify two key issues in the attention mechanism of\nMM-DiT, namely 1) the suppression of cross-modal attention due to token\nimbalance between visual and textual modalities and 2) the lack of\ntimestep-aware attention weighting, which hinder th",
      "published_date": "2025-06-09T13:54:04+00:00",
      "collected_at": "2025-06-10T08:23:10.845425+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "8f6daeb82b06992be91c0048f23bb68d",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal\n  Interaction and Enhancement",
      "url": "https://arxiv.org/abs/2506.07848",
      "description": "Despite recent advances in video generation, existing models still lack\nfine-grained controllability, especially for multi-subject customization with\nconsistent identity and interaction. In this paper, we propose PolyVivid, a\nmulti-subject video customization framework that enables flexible and\nidentity-consistent generation. To establish accurate correspondences between\nsubject images and textual entities, we design a VLLM-based text-image fusion\nmodule that embeds visual identities into the te",
      "published_date": "2025-06-09T11:11:09+00:00",
      "collected_at": "2025-06-10T08:23:10.842334+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "519fa675fc8ebec0877203f1d0b1aa98",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Image Reconstruction as a Tool for Feature Analysis",
      "url": "https://arxiv.org/abs/2506.07803",
      "description": "Vision encoders are increasingly used in modern applications, from\nvision-only models to multimodal systems such as vision-language models.\nDespite their remarkable success, it remains unclear how these architectures\nrepresent features internally. Here, we propose a novel approach for\ninterpreting vision features via image reconstruction. We compare two related\nmodel families, SigLIP and SigLIP2, which differ only in their training\nobjective, and show that encoders pre-trained on image-based tas",
      "published_date": "2025-06-09T10:32:18+00:00",
      "collected_at": "2025-06-10T08:23:10.842883+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "38c059f4ea6298dbf72cdc8da0b6b3a7",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models",
      "url": "https://arxiv.org/abs/2506.07645",
      "description": "Large language models (LLMs) have demonstrated impressive capabilities across\nvarious natural language processing (NLP) tasks in recent years. However, their\nsusceptibility to jailbreaks and perturbations necessitates additional\nevaluations. Many LLMs are multilingual, but safety-related training data\ncontains mainly high-resource languages like English. This can leave them\nvulnerable to perturbations in low-resource languages such as Polish. We show\nhow surprisingly strong attacks can be cheapl",
      "published_date": "2025-06-09T07:09:39+00:00",
      "collected_at": "2025-06-10T08:23:10.841789+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "29ab300e1cbcb911a7936228f42682b8",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Learning What Reinforcement Learning Can't: Interleaved Online\n  Fine-Tuning for Hardest Questions",
      "url": "https://arxiv.org/abs/2506.07527",
      "description": "Recent advances in large language model (LLM) reasoning have shown that\nsophisticated behaviors such as planning and self-reflection can emerge through\nreinforcement learning (RL). However, despite these successes, RL in its\ncurrent form remains insufficient to induce capabilities that exceed the\nlimitations of the base model, as it is primarily optimized based on existing\nknowledge of the model rather than facilitating the acquisition of new\ninformation. To address this limitation, we employ su",
      "published_date": "2025-06-09T04:11:20+00:00",
      "collected_at": "2025-06-10T08:23:10.842605+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "a8ca031f13201575b3180a672ea9a95b",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "SpatialLM: Training Large Language Models for Structured Indoor Modeling",
      "url": "https://arxiv.org/abs/2506.07491",
      "description": "SpatialLM is a large language model designed to process 3D point cloud data\nand generate structured 3D scene understanding outputs. These outputs include\narchitectural elements like walls, doors, windows, and oriented object boxes\nwith their semantic categories. Unlike previous methods which exploit\ntask-specific network designs, our model adheres to the standard multimodal LLM\narchitecture and is fine-tuned directly from open-source LLMs.\n  To train SpatialLM, we collect a large-scale, high-qua",
      "published_date": "2025-06-09T03:10:58+00:00",
      "collected_at": "2025-06-10T08:23:10.845902+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "a1e0690ebabe294c04f5d1ce1c489c20",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large\n  Language Models",
      "url": "https://arxiv.org/abs/2506.07463",
      "description": "We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered\nfor superior data quality and diverse human-like reasoning trajectory. CCI4.0\noccupies roughly 35 TB of disk space and comprises two sub-datasets:\nCCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a 5.2 TB carefully\ncurated Chinese web corpus, a 22.5 TB English subset from Nemotron-CC, and\ndiverse sources from math, wiki, arxiv, and code. Although these data are\nmostly sourced from well-processed datasets, the q",
      "published_date": "2025-06-09T02:14:19+00:00",
      "collected_at": "2025-06-10T08:23:10.845656+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "52c6f6755236133f8929f23bf407b287",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Well Begun is Half Done: Low-resource Preference Alignment by\n  Weak-to-Strong Decoding",
      "url": "https://arxiv.org/abs/2506.07434",
      "description": "Large Language Models (LLMs) require alignment with human preferences to\navoid generating offensive, false, or meaningless content. Recently,\nlow-resource methods for LLM alignment have been popular, while still facing\nchallenges in obtaining both high-quality and aligned content. Motivated by the\nobservation that the difficulty of generating aligned responses is concentrated\nat the beginning of decoding, we propose a novel framework, Weak-to-Strong\nDecoding (WSD), to enhance the alignment abili",
      "published_date": "2025-06-09T01:21:22+00:00",
      "collected_at": "2025-06-10T08:23:10.846589+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "a30e9fb469b80e5ba948f8580b74ef51",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "ConfQA: Answer Only If You Are Confident",
      "url": "https://arxiv.org/abs/2506.07309",
      "description": "Can we teach Large Language Models (LLMs) to refrain from hallucinating\nfactual statements? In this paper we present a fine-tuning strategy that we\ncall ConfQA, which can reduce hallucination rate from 20-40% to under 5% across\nmultiple factuality benchmarks. The core idea is simple: when the LLM answers a\nquestion correctly, it is trained to continue with the answer; otherwise, it is\ntrained to admit \"I am unsure\". But there are two key factors that make the\ntraining highly effective. First, we",
      "published_date": "2025-06-08T18:51:46+00:00",
      "collected_at": "2025-06-10T08:23:10.844179+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "542c25c98748b4f907f12c60caa2ab90",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Pre-trained Large Language Models Learn Hidden Markov Models In-context",
      "url": "https://arxiv.org/abs/2506.07298",
      "description": "Hidden Markov Models (HMMs) are foundational tools for modeling sequential\ndata with latent Markovian structure, yet fitting them to real-world data\nremains computationally challenging. In this work, we show that pre-trained\nlarge language models (LLMs) can effectively model data generated by HMMs via\nin-context learning (ICL)x2013their ability to infer patterns from\nexamples within a prompt. On a diverse set of synthetic HMMs, LLMs achieve\npredictive accuracy approaching the theoretical optimum",
      "published_date": "2025-06-08T17:49:38+00:00",
      "collected_at": "2025-06-10T08:23:10.846129+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "56353b388ba33624b3bc7d1e5e0fa9f1",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path\n  Lengths in LLMs",
      "url": "https://arxiv.org/abs/2506.07240",
      "description": "Recently, techniques such as explicit structured reasoning have demonstrated\nstrong test-time scaling behavior by enforcing a separation between the model's\ninternal \"thinking\" process and the final response. A key factor influencing\nanswer quality in this setting is the length of the thinking stage. When the\nreasoning is too short, the model may fail to capture the complexity of the\ntask. Conversely, when it is too long, the model may overthink, leading to\nunnecessary computation and degraded p",
      "published_date": "2025-06-08T13:54:33+00:00",
      "collected_at": "2025-06-10T08:23:10.844408+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "5d8c127814e641b59a3266a8624b86f7",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "GeometryZero: Improving Geometry Solving for LLM with Group Contrastive\n  Policy Optimization",
      "url": "https://arxiv.org/abs/2506.07160",
      "description": "Recent advances in large language models (LLMs) have demonstrated remarkable\ncapabilities across diverse domains, particularly in mathematical reasoning,\namid which geometry problem solving remains a challenging area where auxiliary\nconstruction plays a enssential role. Existing approaches either achieve\nsuboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring\nmassive computational costs. We posit that reinforcement learning with\nverifiable reward (e.g., GRPO) offers a promising",
      "published_date": "2025-06-08T10:18:15+00:00",
      "collected_at": "2025-06-10T08:23:10.843947+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "53d53caaf4f8bd29e627a1071cfec4c9",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of\n  Reasoning Models via the Lens of Problem Complexity",
      "url": "https://arxiv.org/abs/2506.06941",
      "description": "Recent generations of language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers.\nWhile these models demonstrate improved performance on reasoning benchmarks,\ntheir fundamental capabilities, scaling properties, and limitations remain\ninsufficiently understood. Current evaluations primarily focus on established\nmath and coding benchmarks, emphasizing final answer accuracy. However, this\nevaluation paradigm often suffers from co",
      "published_date": "2025-06-07T18:42:29+00:00",
      "collected_at": "2025-06-10T08:23:10.846360+00:00",
      "author": "",
      "source_priority": 1,
      "score": 93
    },
    {
      "id": "ba0a1d0ca488df04266d6f48441d1523",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "HuggingFace Safetensors Support in PyTorch Distributed Checkpointing",
      "url": "https://pytorch.org/blog/huggingface-safetensors-support-in-pytorch-distributed-checkpointing/",
      "description": "Summary\u00a0 PyTorch Distributed Checkpointing (DCP) is making investments into addressing the interoperability blockers to ensure that popular formats, like HuggingFace safetensors, can work well with PyTorch\u2019s ecosystem. Since HuggingFace has...",
      "published_date": "2025-06-06T19:17:46+00:00",
      "collected_at": "2025-06-10T08:23:11.131280+00:00",
      "author": "Ankita George, Saurabh Mishra, Joe Cummings, Philip Bontrager, Daulet Askarov, Teja Rao, Chien-Chin Huang, Ela Krepska, Jafar Taghiyar",
      "source_priority": 2,
      "score": 92
    },
    {
      "id": "f2e2ef796ae85073f0397c059bcd40ea",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value",
      "url": "https://towardsdatascience.com/not-everything-needs-automation-5-practical-ai-agents-that-deliver-enterprise-value/",
      "description": "What actually works with AI agents inside enterprise organizations?\nThe post Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:54:12+00:00",
      "collected_at": "2025-06-10T08:23:12.529714+00:00",
      "author": "Weiwei Hu",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "3d5ee6adb52013963931f8bccef6033c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling.",
      "url": "https://towardsdatascience.com/prescriptive-modeling-unpacked-a-complete-guide-to-intervention-with-bayesian-modeling/",
      "description": "Learn how to move beyond prediction and actively make intervention through prescriptive modeling. This in-depth guide walks you through Bayesian approaches to system intervention, with practical examples in predictive maintenance.\nThe post Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling. appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:23:32+00:00",
      "collected_at": "2025-06-10T08:23:12.529915+00:00",
      "author": "Erdogan Taskesen",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "cbb488da25d5e23528a79c1c8cdd9eaf",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety\n  Assurance",
      "url": "https://arxiv.org/abs/2506.06444",
      "description": "Existing safety assurance research has primarily focused on training-phase\nalignment to instill safe behaviors into LLMs. However, recent studies have\nexposed these methods' susceptibility to diverse jailbreak attacks.\nConcurrently, inference scaling has significantly advanced LLM reasoning\ncapabilities but remains unexplored in the context of safety assurance.\nAddressing this gap, our work pioneers inference scaling for robust and\neffective LLM safety against emerging threats. We reveal that co",
      "published_date": "2025-06-06T14:05:45+00:00",
      "collected_at": "2025-06-10T08:23:10.845194+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "c47a548516874a370cc7e8aea8b3553d",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Cartridges: Lightweight and general-purpose long context representations\n  via self-study",
      "url": "https://arxiv.org/abs/2506.06266",
      "description": "Large language models are often used to answer queries grounded in large text\ncorpora (e.g. codebases, legal documents, or chat histories) by placing the\nentire corpus in the context window and leveraging in-context learning (ICL).\nAlthough current models support contexts of 100K-1M tokens, this setup is\ncostly to serve because the memory consumption of the KV cache scales with\ninput length. We explore an alternative: training a smaller KV cache offline on\neach corpus. At inference time, we load",
      "published_date": "2025-06-06T13:48:23+00:00",
      "collected_at": "2025-06-10T08:23:10.844640+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "1baeabdb760d5d46d8825a522a214e3e",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How I Automated My Machine Learning Workflow with Just 10 Lines of\u00a0Python",
      "url": "https://towardsdatascience.com/how-i-automated-my-machine-learning-workflow-with-just-10-lines-of-python/",
      "description": "Use LazyPredict and PyCaret to skip the grunt work and jump straight to performance.\nThe post How I Automated My Machine Learning Workflow with Just 10 Lines of\u00a0Python appeared first on Towards Data Science.",
      "published_date": "2025-06-06T13:11:46+00:00",
      "collected_at": "2025-06-10T08:23:12.530115+00:00",
      "author": "Himanshu Sharma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "189d9a77fa5b000dafc2b8d8a009696c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "The Role of Luck in Sports: Can We Measure It?",
      "url": "https://towardsdatascience.com/the-role-of-luck-in-sports-can-we-measure-it/",
      "description": "From last-minute goals to coin tosses: How much does randomness influence the outcomes of games?\nThe post The Role of Luck in Sports: Can We Measure It? appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:56:13+00:00",
      "collected_at": "2025-06-10T08:23:12.530310+00:00",
      "author": "Pol Marin",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "13273eb8ef106c023f296d5889a2003f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Why AI Projects Fail",
      "url": "https://towardsdatascience.com/why-ai-projects-fail/",
      "description": "No one agrees on the exact number, but estimates say anywhere from 50% to 80% of AI projects end in failure.\nThe post Why AI Projects Fail appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:49:02+00:00",
      "collected_at": "2025-06-10T08:23:12.530507+00:00",
      "author": "Ivo Bernardo",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "cc9ddd43ece4c0107e3dc3a3caa42148",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "5 Crucial Tweaks That Will Make Your Charts Accessible to People with Visual Impairments",
      "url": "https://towardsdatascience.com/5-crucial-tweaks-that-will-make-your-charts-accessible-to-people-with-visual-impairments/",
      "description": "More than 350 million people are colorblind - Make sure they can read your visualizations.\nThe post 5 Crucial Tweaks That Will Make Your Charts Accessible to People with Visual Impairments appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:39:46+00:00",
      "collected_at": "2025-06-10T08:23:12.530721+00:00",
      "author": "Dario Rade\u010di\u0107",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "113e2f202f47bdc2db97947155197083",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Proactive Assistant Dialogue Generation from Streaming Egocentric Videos",
      "url": "https://arxiv.org/abs/2506.05904",
      "description": "Recent advances in conversational AI have been substantial, but developing\nreal-time systems for perceptual task guidance remains challenging. These\nsystems must provide interactive, proactive assistance based on streaming\nvisual inputs, yet their development is constrained by the costly and\nlabor-intensive process of data collection and system evaluation. To address\nthese limitations, we present a comprehensive framework with three key\ncontributions. First, we introduce a novel data curation pi",
      "published_date": "2025-06-06T05:23:29+00:00",
      "collected_at": "2025-06-10T08:23:10.842067+00:00",
      "author": "",
      "source_priority": 1,
      "score": 91
    },
    {
      "id": "d7545a1a922f41c500ffbeb3b257c62d",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Introducing the PyTorch Ecosystem Working Group and Project Spotlights",
      "url": "https://pytorch.org/blog/introducing-the-pytorch-ecosystem-working-group-and-project-spotlights/",
      "description": "The PyTorch Ecosystem goes back several years, with some of its earliest projects like Hugging Face, Fast.ai, and PyTorch Lightning going on to grow incredible communities of their own. The...",
      "published_date": "2025-06-05T19:57:09+00:00",
      "collected_at": "2025-06-10T08:23:11.131362+00:00",
      "author": "PyTorch Ecosystem Working Group",
      "source_priority": 2,
      "score": 91
    },
    {
      "id": "53d2e188e38396f9e560fab161ca0546",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "MegaHan97K: A Large-Scale Dataset for Mega-Category Chinese Character\n  Recognition with over 97K Categories",
      "url": "https://arxiv.org/abs/2506.04807",
      "description": "Foundational to the Chinese language and culture, Chinese characters\nencompass extraordinarily extensive and ever-expanding categories, with the\nlatest Chinese GB18030-2022 standard containing 87,887 categories. The accurate\nrecognition of this vast number of characters, termed mega-category\nrecognition, presents a formidable yet crucial challenge for cultural heritage\npreservation and digital applications. Despite significant advances in Optical\nCharacter Recognition (OCR), mega-category recogn",
      "published_date": "2025-06-05T05:33:06+00:00",
      "collected_at": "2025-06-10T08:23:10.843705+00:00",
      "author": "",
      "source_priority": 1,
      "score": 90
    },
    {
      "id": "07911bf4783ae8c988df398024f0a29d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "The Journey from Jupyter to Programmer: A Quick-Start Guide",
      "url": "https://towardsdatascience.com/the-journey-from-jupyter-to-programmer-a-quick-start-guide/",
      "description": "Explore the real benefits of ditching the notebook\nThe post The Journey from Jupyter to Programmer: A Quick-Start Guide appeared first on Towards Data Science.",
      "published_date": "2025-06-04T23:22:34+00:00",
      "collected_at": "2025-06-10T08:23:12.530916+00:00",
      "author": "Lucy Dickinson",
      "source_priority": 3,
      "score": 88
    },
    {
      "id": "6a6aa23d24a1e4c8a12c3043c7f51740",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Building a Modern Dashboard with Python and Gradio",
      "url": "https://towardsdatascience.com/building-a-modern-dashboard-with-python-and-gradio/",
      "description": "Data insights made simple\nThe post Building a Modern Dashboard with Python and Gradio appeared first on Towards Data Science.",
      "published_date": "2025-06-04T22:33:11+00:00",
      "collected_at": "2025-06-10T08:23:12.531107+00:00",
      "author": "Thomas Reid",
      "source_priority": 3,
      "score": 88
    },
    {
      "id": "b1b6d73dcf6dbf65fecf7f79e99c8711",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Open Source AI is Transforming the Economy\u2014Here\u2019s What the Data Shows",
      "url": "https://pytorch.org/blog/open-source-ai-is-transforming-the-economy-heres-what-the-data-shows/",
      "description": "Blog cross-posted on the Linux Foundation blog.\nAs we approach the midpoint of 2025, the potential of AI to transform businesses, economies, and industries is not only widely anticipated and nearly universal but also well documented. In a commissioned project by Meta, LF Research set out to capture existing evidence on this topic, with the specific aim of understanding how open source is playing a role in this transformation.\nIn its latest publication,\u00a0The Economic and Workforce Impacts o",
      "published_date": "2025-06-04T19:31:06+00:00",
      "collected_at": "2025-06-10T08:23:11.133896+00:00",
      "author": "Frank Nagle, Assistant Professor in the Strategy Unit at Harvard Business School and Advising Chief Economist at the Linux Foundation",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "6e80dcb1096a6d87c7d198fb883f6e73",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Build Responsible AI Products with your own Yellow Teaming LLM",
      "url": "https://pytorch.org/blog/build-responsible-ai-products-with-your-own-yellow-teaming-llm/",
      "description": "The tools we use to build AI are evolving fast, with PyTorch at the heart of many advances. But unless we evolve the way we approach building AI systems, we...",
      "published_date": "2025-06-04T14:37:23+00:00",
      "collected_at": "2025-06-10T08:23:11.133981+00:00",
      "author": "Zach Lasiuk, Principal Solutions Designer, Arm",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "aeb2a3a5b979436d7a4d638f220bc43a",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Data Drift Is Not the Actual Problem: Your Monitoring Strategy Is",
      "url": "https://towardsdatascience.com/data-drift-is-not-the-actual-problem-your-monitoring-strategy-is/",
      "description": "Monitoring is easy; what to monitor is not. In the field of machine learning, data drift is\njust noise until you know what it means.\nThe post Data Drift Is Not the Actual Problem: Your Monitoring Strategy Is appeared first on Towards Data Science.",
      "published_date": "2025-06-03T23:24:53+00:00",
      "collected_at": "2025-06-10T08:23:12.531327+00:00",
      "author": "Mahe Jabeen Abdul",
      "source_priority": 3,
      "score": 99
    },
    {
      "id": "2d6cb93f255f8f2835621f7477c42cae",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Reducing Time to Value for Data Science Projects: Part 2",
      "url": "https://towardsdatascience.com/reducing-time-to-value-for-data-science-projects-part-2/",
      "description": "Leveraging automation and parallelism to scale out experiments\nThe post Reducing Time to Value for Data Science Projects: Part 2 appeared first on Towards Data Science.",
      "published_date": "2025-06-03T23:18:14+00:00",
      "collected_at": "2025-06-10T08:23:12.531516+00:00",
      "author": "Kristopher McGlinchey",
      "source_priority": 3,
      "score": 97
    },
    {
      "id": "3b55e34b8685702b557fb90455c481a6",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Pairwise Cross-Variance Classification",
      "url": "https://towardsdatascience.com/pairwise-cross-variance-classification/",
      "description": "Multi-class zero-shot embedding classification and error checking\nThe post Pairwise Cross-Variance Classification appeared first on Towards Data Science.",
      "published_date": "2025-06-03T19:32:49+00:00",
      "collected_at": "2025-06-10T08:23:12.531731+00:00",
      "author": "Doster Esh",
      "source_priority": 3,
      "score": 87
    },
    {
      "id": "7ed05f9c1c2f8bd5caec95c6b41a28d7",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Landing your First Machine Learning Job: Startup vs Big Tech vs Academia",
      "url": "https://towardsdatascience.com/landing-your-first-machine-learning-job-startup-vs-big-tech-vs-academia/",
      "description": "A practical guide to landing your first Machine Learning job across startups, big tech, and academia.\nThe post Landing your First Machine Learning Job: Startup vs Big Tech vs Academia appeared first on Towards Data Science.",
      "published_date": "2025-06-03T19:27:55+00:00",
      "collected_at": "2025-06-10T08:23:12.532058+00:00",
      "author": "Piero Paialunga",
      "source_priority": 3,
      "score": 99
    },
    {
      "id": "d2f00b54f8f60670a623b19b6f330c5d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Decision Trees Natively Handle Categorical Data",
      "url": "https://towardsdatascience.com/decision-trees-natively-handle-categorical-data/",
      "description": "But mean target encoding is their turbocharger\nThe post Decision Trees Natively Handle Categorical Data appeared first on Towards Data Science.",
      "published_date": "2025-06-03T18:27:12+00:00",
      "collected_at": "2025-06-10T08:23:12.532251+00:00",
      "author": "Vadim Arzamasov",
      "source_priority": 3,
      "score": 87
    },
    {
      "id": "944ad331646feb41fcb25a11433a7056",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How to Design My First AI Agent",
      "url": "https://towardsdatascience.com/how-to-design-my-first-ai-agent/",
      "description": "The foundations of designing an AI agent\nThe post How to Design My First AI Agent appeared first on Towards Data Science.",
      "published_date": "2025-06-03T18:19:29+00:00",
      "collected_at": "2025-06-10T08:23:12.532436+00:00",
      "author": "Fabiana Clemente",
      "source_priority": 3,
      "score": 87
    }
  ]
}