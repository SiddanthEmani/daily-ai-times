{
  "category": "Open Source",
  "count": 37,
  "articles": [
    {
      "id": "50915c04bf618d568192a3eb44ce6fec",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Applications of Density Estimation to Legal Theory",
      "url": "https://towardsdatascience.com/applications-of-density-estimation-to-legal-theory/",
      "description": "A brief analysis using density estimation to compare the two-verdict and three-verdict systems.\nThe post Applications of Density Estimation to Legal Theory appeared first on Towards Data Science.",
      "published_date": "2025-06-10T16:36:24+00:00",
      "collected_at": "2025-06-10T20:18:38.015640+00:00",
      "author": "Jimin Kang",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "2cba20a73aaee2108868ab012d464b99",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Mastering SQL Window Functions",
      "url": "https://towardsdatascience.com/mastering-sql-window-functions/",
      "description": "Understand how to use Window Functions to perform calculations without losing\u00a0details\nThe post Mastering SQL Window Functions appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:36:15+00:00",
      "collected_at": "2025-06-10T20:18:38.015873+00:00",
      "author": "Eugenia Anello",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "f85347fb0559744e9a6053beb02e544f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Exploratory Data Analysis: Gamma Spectroscopy in Python",
      "url": "https://towardsdatascience.com/exploratory-data-analysis-gamma-spectroscopy-in-python/",
      "description": "Let\u2019s observe the matter on the atomic level\nThe post Exploratory Data Analysis: Gamma Spectroscopy in Python appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:27:05+00:00",
      "collected_at": "2025-06-10T20:18:38.016092+00:00",
      "author": "Dmitrii Eliuseev",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "b5e500a2d2ad993b7c2a8d260dbc2196",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Bird\u2019s-Eye View of Linear Algebra: Measure of a Map \u2014 Determinants",
      "url": "https://towardsdatascience.com/a-birds-eye-view-of-linear-algebra-measure-of-a-map-determinants/",
      "description": "We roll up our sleeves and start to deal with matrices\nThe post A Bird\u2019s-Eye View of Linear Algebra: Measure of a Map \u2014 Determinants appeared first on Towards Data Science.",
      "published_date": "2025-06-10T05:00:27+00:00",
      "collected_at": "2025-06-10T20:18:38.016321+00:00",
      "author": "Rohit Pandey",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "8974cbf315fc128cbdcbf27fffa994ba",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How to Transition From Data Analyst to Data Scientist",
      "url": "https://towardsdatascience.com/how-to-transition-from-data-analyst-to-data-scientist/",
      "description": "Playbook on how data analysts can become data scientists\nThe post How to Transition From Data Analyst to Data Scientist appeared first on Towards Data Science.",
      "published_date": "2025-06-09T23:09:55+00:00",
      "collected_at": "2025-06-10T20:18:38.016527+00:00",
      "author": "Egor Howell",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "5bb2aa15fbc6f8e0fd06eba34a4606b2",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Trying to Stay Sane in the Age of\u00a0AI",
      "url": "https://towardsdatascience.com/trying-to-stay-sane-in-the-age-of-ai/",
      "description": "A machine learning engineer\u2019s quiet way of not losing her mind\nThe post Trying to Stay Sane in the Age of\u00a0AI appeared first on Towards Data Science.",
      "published_date": "2025-06-09T22:50:40+00:00",
      "collected_at": "2025-06-10T20:18:38.016737+00:00",
      "author": "Amy Ma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "fabcafc421299f350d8703f2c53b346b",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Play to Generalize: Learning to Reason Through Game Play",
      "url": "https://arxiv.org/abs/2506.08011",
      "description": "Developing generalizable reasoning capabilities in multimodal large language\nmodels (MLLMs) remains challenging. Motivated by cognitive science literature\nsuggesting that gameplay promotes transferable cognitive skills, we propose a\nnovel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs\ndevelop out-of-domain generalization of multimodal reasoning through playing\narcade-like games. Specifically, we show that post-training a 7B-parameter MLLM\nvia reinforcement learning (RL) on s",
      "published_date": "2025-06-09T13:59:57+00:00",
      "collected_at": "2025-06-10T20:18:36.238913+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "e8d065eae704eddc032550cdcaacc943",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Dynamic View Synthesis as an Inverse Problem",
      "url": "https://arxiv.org/abs/2506.08004",
      "description": "In this work, we address dynamic view synthesis from monocular videos as an\ninverse problem in a training-free setting. By redesigning the noise\ninitialization phase of a pre-trained video diffusion model, we enable\nhigh-fidelity dynamic view synthesis without any weight updates or auxiliary\nmodules. We begin by identifying a fundamental obstacle to deterministic\ninversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and\nresolve it by introducing a novel noise representation,",
      "published_date": "2025-06-09T13:59:47+00:00",
      "collected_at": "2025-06-10T20:18:36.234684+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "6122a3620b58a26327ff5ef77e632285",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "\u03c4^2-Bench: Evaluating Conversational Agents in a Dual-Control\n  Environment",
      "url": "https://arxiv.org/abs/2506.07982",
      "description": "Existing benchmarks for conversational AI agents simulate single-control\nenvironments, where only the AI agent can use tools to interact with the world,\nwhile the user remains a passive information provider. This differs from\nreal-world scenarios like technical support, where users need to actively\nparticipate in modifying the state of the (shared) world. In order to address\nthis gap, we introduce tau^2-bench, with four key contributions:\n  1) A novel Telecom dual-control domain modeled as a Dec",
      "published_date": "2025-06-09T13:52:18+00:00",
      "collected_at": "2025-06-10T20:18:36.236146+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "f52abc8a7425ece6ecd31e9f3ccec907",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "CyberV: Cybernetics for Test-time Scaling in Video Understanding",
      "url": "https://arxiv.org/abs/2506.07971",
      "description": "Current Multimodal Large Language Models (MLLMs) may struggle with\nunderstanding long or complex videos due to computational demands at test time,\nlack of robustness, and limited accuracy, primarily stemming from their\nfeed-forward processing nature. These limitations could be more severe for\nmodels with fewer parameters. To address these limitations, we propose a novel\nframework inspired by cybernetic principles, redesigning video MLLMs as\nadaptive systems capable of self-monitoring, self-corre",
      "published_date": "2025-06-09T13:45:18+00:00",
      "collected_at": "2025-06-10T20:18:36.237505+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "8f6daeb82b06992be91c0048f23bb68d",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal\n  Interaction and Enhancement",
      "url": "https://arxiv.org/abs/2506.07848",
      "description": "Despite recent advances in video generation, existing models still lack\nfine-grained controllability, especially for multi-subject customization with\nconsistent identity and interaction. In this paper, we propose PolyVivid, a\nmulti-subject video customization framework that enables flexible and\nidentity-consistent generation. To establish accurate correspondences between\nsubject images and textual entities, we design a VLLM-based text-image fusion\nmodule that embeds visual identities into the te",
      "published_date": "2025-06-09T11:11:09+00:00",
      "collected_at": "2025-06-10T20:18:36.240236+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "083e6db4fc83d171464c24afb9e889d9",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Improving large language models with concept-aware fine-tuning",
      "url": "https://arxiv.org/abs/2506.07833",
      "description": "Large language models (LLMs) have become the cornerstone of modern AI.\nHowever, the existing paradigm of next-token prediction fundamentally limits\ntheir ability to form coherent, high-level concepts, making it a critical\nbarrier to human-like understanding and reasoning. Take the phrase \"ribonucleic\nacid\" as an example: an LLM will first decompose it into tokens, i.e.,\nartificial text fragments (\"rib\", \"on\", ...), then learn each token\nsequentially, rather than grasping the phrase as a unified,",
      "published_date": "2025-06-09T10:55:00+00:00",
      "collected_at": "2025-06-10T20:18:36.239130+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "38c059f4ea6298dbf72cdc8da0b6b3a7",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models",
      "url": "https://arxiv.org/abs/2506.07645",
      "description": "Large language models (LLMs) have demonstrated impressive capabilities across\nvarious natural language processing (NLP) tasks in recent years. However, their\nsusceptibility to jailbreaks and perturbations necessitates additional\nevaluations. Many LLMs are multilingual, but safety-related training data\ncontains mainly high-resource languages like English. This can leave them\nvulnerable to perturbations in low-resource languages such as Polish. We show\nhow surprisingly strong attacks can be cheapl",
      "published_date": "2025-06-09T07:09:39+00:00",
      "collected_at": "2025-06-10T20:18:36.239800+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "649114649cbcb5cae6329b76e8cdb1e7",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional\n  Autonomous Agent Systems",
      "url": "https://arxiv.org/abs/2506.07564",
      "description": "Recent advances in large language models (LLMs) and vision-language models\n(VLMs) have enabled powerful autonomous agents capable of complex reasoning and\nmulti-modal tool use. Despite their growing capabilities, today's agent\nframeworks remain fragile, lacking principled mechanisms for secure information\nflow, reliability, and multi-agent coordination. In this work, we introduce\nSAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based\nagents. SAFEFLOW enforces fine-graine",
      "published_date": "2025-06-09T05:04:37+00:00",
      "collected_at": "2025-06-10T20:18:36.235448+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "6a2125df1828c430a6dd196519658ffd",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering",
      "url": "https://arxiv.org/abs/2506.06905",
      "description": "Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to\nperform new tasks with minimal supervision. However, ICL performance,\nespecially in smaller LMMs, is inconsistent and does not always improve\nmonotonically with increasing examples. We hypothesize that this occurs due to\nthe LMM being overwhelmed by additional information present in the image\nembeddings, which is not required for the downstream task. To address this, we\npropose a meta-learning approach that provides an alt",
      "published_date": "2025-06-07T15:37:22+00:00",
      "collected_at": "2025-06-10T20:18:36.238432+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "fca813e798b48bb7264a0d44d7af0780",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Self-Adapting Improvement Loops for Robotic Learning",
      "url": "https://arxiv.org/abs/2506.06658",
      "description": "Video generative models trained on expert demonstrations have been utilized\nas performant text-conditioned visual planners for solving robotic tasks.\nHowever, generalization to unseen tasks remains a challenge. Whereas improved\ngeneralization may be facilitated by leveraging learned prior knowledge from\nadditional pre-collected offline data sources, such as web-scale video\ndatasets, in the era of experience we aim to design agents that can\ncontinuously improve in an online manner from self-colle",
      "published_date": "2025-06-07T00:34:37+00:00",
      "collected_at": "2025-06-10T20:18:36.236804+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "ba0a1d0ca488df04266d6f48441d1523",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "HuggingFace Safetensors Support in PyTorch Distributed Checkpointing",
      "url": "https://pytorch.org/blog/huggingface-safetensors-support-in-pytorch-distributed-checkpointing/",
      "description": "Summary\u00a0 PyTorch Distributed Checkpointing (DCP) is making investments into addressing the interoperability blockers to ensure that popular formats, like HuggingFace safetensors, can work well with PyTorch\u2019s ecosystem. Since HuggingFace has...",
      "published_date": "2025-06-06T19:17:46+00:00",
      "collected_at": "2025-06-10T20:18:36.583901+00:00",
      "author": "Ankita George, Saurabh Mishra, Joe Cummings, Philip Bontrager, Daulet Askarov, Teja Rao, Chien-Chin Huang, Ela Krepska, Jafar Taghiyar",
      "source_priority": 2,
      "score": 91
    },
    {
      "id": "f2e2ef796ae85073f0397c059bcd40ea",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value",
      "url": "https://towardsdatascience.com/not-everything-needs-automation-5-practical-ai-agents-that-deliver-enterprise-value/",
      "description": "What actually works with AI agents inside enterprise organizations?\nThe post Not Everything Needs Automation: 5 Practical AI Agents That Deliver Enterprise Value appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:54:12+00:00",
      "collected_at": "2025-06-10T20:18:38.016938+00:00",
      "author": "Weiwei Hu",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "3d5ee6adb52013963931f8bccef6033c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling.",
      "url": "https://towardsdatascience.com/prescriptive-modeling-unpacked-a-complete-guide-to-intervention-with-bayesian-modeling/",
      "description": "Learn how to move beyond prediction and actively make intervention through prescriptive modeling. This in-depth guide walks you through Bayesian approaches to system intervention, with practical examples in predictive maintenance.\nThe post Prescriptive Modeling Unpacked: A Complete Guide to Intervention With Bayesian Modeling. appeared first on Towards Data Science.",
      "published_date": "2025-06-06T17:23:32+00:00",
      "collected_at": "2025-06-10T20:18:38.017139+00:00",
      "author": "Erdogan Taskesen",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "b74815118053d89840495b18ab2f213c",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge\n  Conflict on Large Language Models",
      "url": "https://arxiv.org/abs/2506.06485",
      "description": "Large language models frequently rely on both contextual input and parametric\nknowledge to perform tasks. However, these sources can come into conflict,\nespecially when retrieved documents contradict the model's parametric\nknowledge. We propose a diagnostic framework to systematically evaluate LLM\nbehavior under context-memory conflict, where the contextual information\ndiverges from their parametric beliefs. We construct diagnostic data that\nelicit these conflicts and analyze model performance a",
      "published_date": "2025-06-06T15:20:23+00:00",
      "collected_at": "2025-06-10T20:18:36.237789+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "1baeabdb760d5d46d8825a522a214e3e",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "How I Automated My Machine Learning Workflow with Just 10 Lines of\u00a0Python",
      "url": "https://towardsdatascience.com/how-i-automated-my-machine-learning-workflow-with-just-10-lines-of-python/",
      "description": "Use LazyPredict and PyCaret to skip the grunt work and jump straight to performance.\nThe post How I Automated My Machine Learning Workflow with Just 10 Lines of\u00a0Python appeared first on Towards Data Science.",
      "published_date": "2025-06-06T13:11:46+00:00",
      "collected_at": "2025-06-10T20:18:38.017361+00:00",
      "author": "Himanshu Sharma",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "189d9a77fa5b000dafc2b8d8a009696c",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "The Role of Luck in Sports: Can We Measure It?",
      "url": "https://towardsdatascience.com/the-role-of-luck-in-sports-can-we-measure-it/",
      "description": "From last-minute goals to coin tosses: How much does randomness influence the outcomes of games?\nThe post The Role of Luck in Sports: Can We Measure It? appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:56:13+00:00",
      "collected_at": "2025-06-10T20:18:38.017563+00:00",
      "author": "Pol Marin",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "13273eb8ef106c023f296d5889a2003f",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Why AI Projects Fail",
      "url": "https://towardsdatascience.com/why-ai-projects-fail/",
      "description": "No one agrees on the exact number, but estimates say anywhere from 50% to 80% of AI projects end in failure.\nThe post Why AI Projects Fail appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:49:02+00:00",
      "collected_at": "2025-06-10T20:18:38.017772+00:00",
      "author": "Ivo Bernardo",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "cc9ddd43ece4c0107e3dc3a3caa42148",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "5 Crucial Tweaks That Will Make Your Charts Accessible to People with Visual Impairments",
      "url": "https://towardsdatascience.com/5-crucial-tweaks-that-will-make-your-charts-accessible-to-people-with-visual-impairments/",
      "description": "More than 350 million people are colorblind - Make sure they can read your visualizations.\nThe post 5 Crucial Tweaks That Will Make Your Charts Accessible to People with Visual Impairments appeared first on Towards Data Science.",
      "published_date": "2025-06-06T12:39:46+00:00",
      "collected_at": "2025-06-10T20:18:38.017992+00:00",
      "author": "Dario Rade\u010di\u0107",
      "source_priority": 3,
      "score": 90
    },
    {
      "id": "4baaeab77665d1395a738a3d64ed4c06",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal\n  Learning",
      "url": "https://arxiv.org/abs/2506.06205",
      "description": "Modern robot navigation systems encounter difficulties in diverse and complex\nindoor environments. Traditional approaches rely on multiple modules with small\nmodels or rule-based systems and thus lack adaptability to new environments. To\naddress this, we developed Astra, a comprehensive dual-model architecture,\nAstra-Global and Astra-Local, for mobile robot navigation. Astra-Global, a\nmultimodal LLM, processes vision and language inputs to perform self and goal\nlocalization using a hybrid topolo",
      "published_date": "2025-06-06T12:08:47+00:00",
      "collected_at": "2025-06-10T20:18:36.239588+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "151f64a16ed83f25771fd117b7fa771b",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Bootstrapping World Models from Dynamics Models in Multimodal Foundation\n  Models",
      "url": "https://arxiv.org/abs/2506.06006",
      "description": "To what extent do vision-and-language foundation models possess a realistic\nworld model (observation times action rightarrow observation) and a\ndynamics model (observation times observation rightarrow action), when\nactions are expressed through language? While open-source foundation models\nstruggle with both, we find that fine-tuning them to acquire a dynamics model\nthrough supervision is significantly easier than acquiring a world model. In\nturn, dynamics models can be used to bootstrap world m",
      "published_date": "2025-06-06T07:50:18+00:00",
      "collected_at": "2025-06-10T20:18:36.239370+00:00",
      "author": "",
      "source_priority": 1,
      "score": 98
    },
    {
      "id": "113e2f202f47bdc2db97947155197083",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Proactive Assistant Dialogue Generation from Streaming Egocentric Videos",
      "url": "https://arxiv.org/abs/2506.05904",
      "description": "Recent advances in conversational AI have been substantial, but developing\nreal-time systems for perceptual task guidance remains challenging. These\nsystems must provide interactive, proactive assistance based on streaming\nvisual inputs, yet their development is constrained by the costly and\nlabor-intensive process of data collection and system evaluation. To address\nthese limitations, we present a comprehensive framework with three key\ncontributions. First, we introduce a novel data curation pi",
      "published_date": "2025-06-06T05:23:29+00:00",
      "collected_at": "2025-06-10T20:18:36.240016+00:00",
      "author": "",
      "source_priority": 1,
      "score": 90
    },
    {
      "id": "d7545a1a922f41c500ffbeb3b257c62d",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Introducing the PyTorch Ecosystem Working Group and Project Spotlights",
      "url": "https://pytorch.org/blog/introducing-the-pytorch-ecosystem-working-group-and-project-spotlights/",
      "description": "The PyTorch Ecosystem goes back several years, with some of its earliest projects like Hugging Face, Fast.ai, and PyTorch Lightning going on to grow incredible communities of their own. The...",
      "published_date": "2025-06-05T19:57:09+00:00",
      "collected_at": "2025-06-10T20:18:36.584016+00:00",
      "author": "PyTorch Ecosystem Working Group",
      "source_priority": 2,
      "score": 90
    },
    {
      "id": "602f7ae04d16b8310e315d22d38c873a",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward\n  Models in LLMs",
      "url": "https://arxiv.org/abs/2506.05598",
      "description": "Recent calls for pluralistic alignment of Large Language Models (LLMs)\nencourage adapting models to diverse user preferences. However, most prior work\non personalized reward models heavily rely on additional identity information,\nsuch as demographic details or a predefined set of preference categories. To\nthis end, we introduce SynthesizeMe, an approach to inducing synthetic user\npersonas from user interactions for personalized reward modeling. SynthesizeMe\nfirst generates and verifies reasoning",
      "published_date": "2025-06-05T17:23:16+00:00",
      "collected_at": "2025-06-10T20:18:36.237211+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "4b8afaced3d7ab4420f788a53f7988bf",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Debatable Intelligence: Benchmarking LLM Judges via Debate Speech\n  Evaluation",
      "url": "https://arxiv.org/abs/2506.05062",
      "description": "We introduce Debate Speech Evaluation as a novel and challenging benchmark\nfor assessing LLM judges. Evaluating debate speeches requires a deep\nunderstanding of the speech at multiple levels, including argument strength and\nrelevance, the coherence and organization of the speech, the appropriateness of\nits style and tone, and so on. This task involves a unique set of cognitive\nabilities that have previously received limited attention in systematic LLM\nbenchmarking. To explore such skills, we lev",
      "published_date": "2025-06-05T10:06:51+00:00",
      "collected_at": "2025-06-10T20:18:36.238682+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "3fd2c9f9d684bc96e1e7da41814f0459",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning",
      "url": "https://arxiv.org/abs/2506.04651",
      "description": "Recent advances in LLMs have enabled their use as autonomous agents across a\nrange of tasks, yet they continue to struggle with formulating and adhering to\ncoherent long-term strategies. In this paper, we investigate whether LLM agents\ncan self-improve when placed in environments that explicitly challenge their\nstrategic planning abilities. Using the board game Settlers of Catan, accessed\nthrough the open-source Catanatron framework, we benchmark a progression of\nLLM-based agents, from a simple",
      "published_date": "2025-06-05T01:45:24+00:00",
      "collected_at": "2025-06-10T20:18:36.235828+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "07911bf4783ae8c988df398024f0a29d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "The Journey from Jupyter to Programmer: A Quick-Start Guide",
      "url": "https://towardsdatascience.com/the-journey-from-jupyter-to-programmer-a-quick-start-guide/",
      "description": "Explore the real benefits of ditching the notebook\nThe post The Journey from Jupyter to Programmer: A Quick-Start Guide appeared first on Towards Data Science.",
      "published_date": "2025-06-04T23:22:34+00:00",
      "collected_at": "2025-06-10T20:18:38.018206+00:00",
      "author": "Lucy Dickinson",
      "source_priority": 3,
      "score": 88
    },
    {
      "id": "6a6aa23d24a1e4c8a12c3043c7f51740",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Building a Modern Dashboard with Python and Gradio",
      "url": "https://towardsdatascience.com/building-a-modern-dashboard-with-python-and-gradio/",
      "description": "Data insights made simple\nThe post Building a Modern Dashboard with Python and Gradio appeared first on Towards Data Science.",
      "published_date": "2025-06-04T22:33:11+00:00",
      "collected_at": "2025-06-10T20:18:38.018423+00:00",
      "author": "Thomas Reid",
      "source_priority": 3,
      "score": 88
    },
    {
      "id": "b1b6d73dcf6dbf65fecf7f79e99c8711",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Open Source AI is Transforming the Economy\u2014Here\u2019s What the Data Shows",
      "url": "https://pytorch.org/blog/open-source-ai-is-transforming-the-economy-heres-what-the-data-shows/",
      "description": "Blog cross-posted on the Linux Foundation blog.\nAs we approach the midpoint of 2025, the potential of AI to transform businesses, economies, and industries is not only widely anticipated and nearly universal but also well documented. In a commissioned project by Meta, LF Research set out to capture existing evidence on this topic, with the specific aim of understanding how open source is playing a role in this transformation.\nIn its latest publication,\u00a0The Economic and Workforce Impacts o",
      "published_date": "2025-06-04T19:31:06+00:00",
      "collected_at": "2025-06-10T20:18:36.586656+00:00",
      "author": "Frank Nagle, Assistant Professor in the Strategy Unit at Harvard Business School and Advising Chief Economist at the Linux Foundation",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "6e80dcb1096a6d87c7d198fb883f6e73",
      "source_id": "pytorch_blog",
      "source": "Blog \u2013 PyTorch",
      "category": "Open Source",
      "title": "Build Responsible AI Products with your own Yellow Teaming LLM",
      "url": "https://pytorch.org/blog/build-responsible-ai-products-with-your-own-yellow-teaming-llm/",
      "description": "The tools we use to build AI are evolving fast, with PyTorch at the heart of many advances. But unless we evolve the way we approach building AI systems, we...",
      "published_date": "2025-06-04T14:37:23+00:00",
      "collected_at": "2025-06-10T20:18:36.586751+00:00",
      "author": "Zach Lasiuk, Principal Solutions Designer, Arm",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "aeb2a3a5b979436d7a4d638f220bc43a",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Data Drift Is Not the Actual Problem: Your Monitoring Strategy Is",
      "url": "https://towardsdatascience.com/data-drift-is-not-the-actual-problem-your-monitoring-strategy-is/",
      "description": "Monitoring is easy; what to monitor is not. In the field of machine learning, data drift is\njust noise until you know what it means.\nThe post Data Drift Is Not the Actual Problem: Your Monitoring Strategy Is appeared first on Towards Data Science.",
      "published_date": "2025-06-03T23:24:53+00:00",
      "collected_at": "2025-06-10T20:18:38.018649+00:00",
      "author": "Mahe Jabeen Abdul",
      "source_priority": 3,
      "score": 99
    },
    {
      "id": "2d6cb93f255f8f2835621f7477c42cae",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Reducing Time to Value for Data Science Projects: Part 2",
      "url": "https://towardsdatascience.com/reducing-time-to-value-for-data-science-projects-part-2/",
      "description": "Leveraging automation and parallelism to scale out experiments\nThe post Reducing Time to Value for Data Science Projects: Part 2 appeared first on Towards Data Science.",
      "published_date": "2025-06-03T23:18:14+00:00",
      "collected_at": "2025-06-10T20:18:38.018845+00:00",
      "author": "Kristopher McGlinchey",
      "source_priority": 3,
      "score": 97
    }
  ]
}