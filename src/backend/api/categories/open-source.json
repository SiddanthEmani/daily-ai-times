{
  "category": "Open Source",
  "count": 39,
  "articles": [
    {
      "id": "2abc9316027cf7d3eef7a0b93cc58657",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Understanding Matrices | Part 2: Matrix-Matrix Multiplication",
      "url": "https://towardsdatascience.com/understanding-matrices-part-2-matrix-matrix-multiplication/",
      "description": "The physical meaning of multiplying two matrices and how it works on several special matrices.\nThe post Understanding Matrices | Part 2: Matrix-Matrix Multiplication appeared first on Towards Data Science.",
      "published_date": "2025-06-19T19:21:58+00:00",
      "collected_at": "2025-06-19T20:19:43.882179+00:00",
      "author": "Tigran Hayrapetyan",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "4c3beb20e4d88b07f9501072b4a7e164",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "LLM-as-a-Judge: A Practical Guide",
      "url": "https://towardsdatascience.com/llm-as-a-judge-a-practical-guide/",
      "description": "How to Scale LLM Evaluations Beyond Manual Review\nThe post LLM-as-a-Judge: A Practical Guide appeared first on Towards Data Science.",
      "published_date": "2025-06-19T19:03:29+00:00",
      "collected_at": "2025-06-19T20:19:43.882406+00:00",
      "author": "Shuai Guo",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "188245a0ce84b7d943b06522be01feb0",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "From Configuration to Orchestration: Building an ETL Workflow with AWS Is No Longer a Struggle",
      "url": "https://towardsdatascience.com/from-configuration-to-orchestration-building-etl-workflow-with-aws-is-no-longer-struggling/",
      "description": "A step-by-step guide to leverage AWS services for efficient data pipeline automation\nThe post From Configuration to Orchestration: Building an ETL Workflow with AWS Is No Longer a Struggle appeared first on Towards Data Science.",
      "published_date": "2025-06-19T17:04:15+00:00",
      "collected_at": "2025-06-19T20:19:43.882605+00:00",
      "author": "Jiayan Yin",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "a2d983aec8ee0521ab5bef979d69e7ed",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "What PyTorch Really Means by a Leaf Tensor and Its Grad",
      "url": "https://towardsdatascience.com/what-pytorch-really-means-by-a-leaf-tensor-2/",
      "description": "The secret life of leaves, gradients, and the mighty requires_grad flag\nThe post What PyTorch Really Means by a Leaf Tensor and Its Grad appeared first on Towards Data Science.",
      "published_date": "2025-06-19T16:43:18+00:00",
      "collected_at": "2025-06-19T20:19:43.882800+00:00",
      "author": "Maciej J. Mikulski",
      "source_priority": 3,
      "score": 95
    },
    {
      "id": "63150bbafe9d932ce94916bcf699d3e2",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Beyond Code Generation: Continuously Evolve Text with LLMs",
      "url": "https://towardsdatascience.com/beyond-code-generation-continuously-evolve-text-with-llms/",
      "description": "Long-running content evolution and an introduction to result analysis\nThe post Beyond Code Generation: Continuously Evolve Text with LLMs appeared first on Towards Data Science.",
      "published_date": "2025-06-19T05:33:40+00:00",
      "collected_at": "2025-06-19T20:19:43.882994+00:00",
      "author": "Julian Mendel",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "7115739154e9e4efe2ee5f480dbace25",
      "source_id": "pytorch_blog",
      "source": "Blog – PyTorch",
      "category": "Open Source",
      "title": "PyTorch Docathon 2025: Wrap Up",
      "url": "https://pytorch.org/blog/pytorch-docathon-2025-wrap-up/",
      "description": "Huge congratulations and a massive thank you to all the amazing participants of the PyTorch Docathon 2025! Over the past two weeks (June 3rd-15th), our virtual Docathon brought together over...",
      "published_date": "2025-06-18T21:55:11+00:00",
      "collected_at": "2025-06-19T20:19:42.561102+00:00",
      "author": "PyTorch Foundation",
      "source_priority": 2,
      "score": 96
    },
    {
      "id": "48bf20a7a4efdc9c7e5830baf66ebdbc",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Animating Linear Transformations with Quiver",
      "url": "https://towardsdatascience.com/animating-linear-transformations-with-quiver/",
      "description": "A useful tool in your quiver\nThe post Animating Linear Transformations with Quiver appeared first on Towards Data Science.",
      "published_date": "2025-06-18T19:27:47+00:00",
      "collected_at": "2025-06-19T20:19:43.883191+00:00",
      "author": "Artemij Lehmann",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "00329eb786aa121236e9b37d4925a596",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Multi-Agent SQL Assistant You Can Trust with Human-in-Loop Checkpoint & LLM Cost Control",
      "url": "https://towardsdatascience.com/a-multi-agent-sql-assistant-you-can-trust-with-human-in-loop-checkpoint-llm-cost-control/",
      "description": "Your very own SQL assistant built with Streamlit, SQLite, & CrewAI\nThe post A Multi-Agent SQL Assistant You Can Trust with Human-in-Loop Checkpoint & LLM Cost Control appeared first on Towards Data Science.",
      "published_date": "2025-06-18T18:31:01+00:00",
      "collected_at": "2025-06-19T20:19:43.929833+00:00",
      "author": "Alle Sravani",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "20ca0310df8128a6de70f59c24acc8e8",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Can We Use Chess to Predict Soccer?",
      "url": "https://towardsdatascience.com/can-we-use-chess-to-predict-soccer/",
      "description": "An adaptation of Elo ratings for soccer implemented in Python\nThe post Can We Use Chess to Predict Soccer? appeared first on Towards Data Science.",
      "published_date": "2025-06-18T17:47:34+00:00",
      "collected_at": "2025-06-19T20:19:43.930085+00:00",
      "author": "Felipe Bandeira",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "3551c2b6755e595e6216290e15c45b74",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Computer Vision’s Annotation Bottleneck Is Finally Breaking",
      "url": "https://towardsdatascience.com/computer-visions-annotation-bottleneck-is-finally-breaking/",
      "description": "A Technical Deep Dive into Auto-Labeling\nThe post Computer Vision’s Annotation Bottleneck Is Finally Breaking appeared first on Towards Data Science.",
      "published_date": "2025-06-18T17:13:29+00:00",
      "collected_at": "2025-06-19T20:19:43.930315+00:00",
      "author": "TDS Brand Studio",
      "source_priority": 3,
      "score": 94
    },
    {
      "id": "7098de49c64233058ee854c576f05306",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Why Open Source is No Longer Optional — And How to Make it Work for Your Business",
      "url": "https://towardsdatascience.com/why-open-source-is-no-longer-optional-and-how-to-make-it-work-for-your-business/",
      "description": "To stay ahead, open source is the only way.\nThe post Why Open Source is No Longer Optional — And How to Make it Work for Your Business appeared first on Towards Data Science.",
      "published_date": "2025-06-18T16:01:38+00:00",
      "collected_at": "2025-06-19T20:19:43.930527+00:00",
      "author": "Laura Sellers",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "a6eb4bc78ff4528c7c752bf17cd22020",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Evolutionary Caching to Accelerate Your Off-the-Shelf Diffusion Model",
      "url": "https://arxiv.org/abs/2506.15682",
      "description": "Diffusion-based image generation models excel at producing high-quality\nsynthetic content, but suffer from slow and computationally expensive\ninference. Prior work has attempted to mitigate this by caching and reusing\nfeatures within diffusion transformers across inference steps. These methods,\nhowever, often rely on rigid heuristics that result in limited acceleration or\npoor generalization across architectures. We propose Evolutionary Caching to\nAccelerate Diffusion models (ECAD), a genetic al",
      "published_date": "2025-06-18T13:59:50+00:00",
      "collected_at": "2025-06-19T20:19:42.456186+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "ce1c284b34ad4b48698d8b6c8448c076",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "GenRecal: Generation after Recalibration from Large to Small\n  Vision-Language Models",
      "url": "https://arxiv.org/abs/2506.15681",
      "description": "Recent advancements in vision-language models (VLMs) have leveraged large\nlanguage models (LLMs) to achieve performance on par with closed-source systems\nlike GPT-4V. However, deploying these models in real-world scenarios,\nparticularly on resource-constrained devices, remains challenging due to their\nsubstantial computational demands. This has spurred interest in distilling\nknowledge from large VLMs into smaller, more efficient counterparts. A key\nchallenge arises here from the diversity of VLM",
      "published_date": "2025-06-18T13:59:49+00:00",
      "collected_at": "2025-06-19T20:19:42.460077+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "a9f288b189e3aefa9ec7419d7445b324",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated\n  Agent Intelligence",
      "url": "https://arxiv.org/abs/2506.15677",
      "description": "AI agents today are mostly siloed - they either retrieve and reason over vast\namount of digital information and knowledge obtained online; or interact with\nthe physical world through embodied perception, planning and action - but\nrarely both. This separation limits their ability to solve tasks that require\nintegrated physical and digital intelligence, such as cooking from online\nrecipes, navigating with dynamic map data, or interpreting real-world landmarks\nusing web knowledge. We introduce Embo",
      "published_date": "2025-06-18T13:58:17+00:00",
      "collected_at": "2025-06-19T20:19:42.460620+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "ce7e6b3a40ac1e8db017b64a31587c38",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Sekai: A Video Dataset towards World Exploration",
      "url": "https://arxiv.org/abs/2506.15675",
      "description": "Video generation techniques have made remarkable progress, promising to be\nthe foundation of interactive world exploration. However, existing video\ngeneration datasets are not well-suited for world exploration training as they\nsuffer from some limitations: limited locations, short duration, static scenes,\nand a lack of annotations about exploration and the world. In this paper, we\nintroduce Sekai (meaning ``world'' in Japanese), a high-quality first-person\nview worldwide video dataset with rich",
      "published_date": "2025-06-18T13:57:06+00:00",
      "collected_at": "2025-06-19T20:19:42.459398+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "dc813b4ef014ed7aabb3ff9779a658b0",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via\n  Swarm Intelligence",
      "url": "https://arxiv.org/abs/2506.15672",
      "description": "The rapid progress of Large Language Models has advanced agentic systems in\ndecision-making, coordination, and task execution. Yet, existing agentic system\ngeneration frameworks lack full autonomy, missing from-scratch agent\ngeneration, self-optimizing agent functionality, and collaboration, limiting\nadaptability and scalability. We propose SwarmAgentic, a framework for fully\nautomated agentic system generation that constructs agentic systems from\nscratch and jointly optimizes agent functionalit",
      "published_date": "2025-06-18T13:54:55+00:00",
      "collected_at": "2025-06-19T20:19:42.458696+00:00",
      "author": "",
      "source_priority": 1,
      "score": 95
    },
    {
      "id": "8558f6d3cbc755d128861c86ddc4ec0d",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "SciVer: Evaluating Foundation Models for Multimodal Scientific Claim\n  Verification",
      "url": "https://arxiv.org/abs/2506.15569",
      "description": "We introduce SciVer, the first benchmark specifically designed to evaluate\nthe ability of foundation models to verify claims within a multimodal\nscientific context. SciVer consists of 3,000 expert-annotated examples over\n1,113 scientific papers, covering four subsets, each representing a common\nreasoning type in multimodal scientific claim verification. To enable\nfine-grained evaluation, each example includes expert-annotated supporting\nevidence. We assess the performance of 21 state-of-the-art",
      "published_date": "2025-06-18T11:43:26+00:00",
      "collected_at": "2025-06-19T20:19:42.459624+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "c07c6303936468e7aab11e1ec6c7358f",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "All is Not Lost: LLM Recovery without Checkpoints",
      "url": "https://arxiv.org/abs/2506.15461",
      "description": "Training LLMs on decentralized and wimpy computation nodes, e.g., multiple\non-spot instances, lowers the training cost and enables model democratization.\nThe inevitable challenge here is the churn of nodes due to failures and the\noperator's scheduling policies, leading to losing a stage - a part of the\nmodel. The conventional approaches to recover from failures are to either use\ncheckpointing, where periodically a copy of the entire model is sent to an\nadditional storage, or redundant computatio",
      "published_date": "2025-06-18T09:48:33+00:00",
      "collected_at": "2025-06-19T20:19:42.455905+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "4f9488b381a9a0c28948fa7eff9f27d1",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning\n  in LLMs",
      "url": "https://arxiv.org/abs/2506.15211",
      "description": "Recent advances in Large Reasoning Models (LRMs) trained with Long\nChain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain\ngeneralization capabilities. However, the underlying mechanisms supporting such\ntransfer remain poorly understood. We hypothesize that cross-domain\ngeneralization arises from shared abstract reasoning prototypes -- fundamental\nreasoning patterns that capture the essence of problems across domains. These\nprototypes minimize the nuances of the represent",
      "published_date": "2025-06-18T03:44:09+00:00",
      "collected_at": "2025-06-19T20:19:42.457925+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "63a113be7db3662f6d0529a921d6e3c7",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Abstract Classes: A Software Engineering Concept Data Scientists Must Know To Succeed",
      "url": "https://towardsdatascience.com/abstract-classes-a-software-engineering-concept-data-scientists-must-know-to-succeed/",
      "description": "Simple concepts that differentiate a professional from amateurs.\nThe post Abstract Classes: A Software Engineering Concept Data Scientists Must Know To Succeed appeared first on Towards Data Science.",
      "published_date": "2025-06-17T22:45:07+00:00",
      "collected_at": "2025-06-19T20:19:43.930720+00:00",
      "author": "Benjamin Lee",
      "source_priority": 3,
      "score": 93
    },
    {
      "id": "36127b78b393883c821cfc41a73e3969",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form\n  Generation",
      "url": "https://arxiv.org/abs/2506.15068",
      "description": "Evaluating open-ended long-form generation is challenging because it is hard\nto define what clearly separates good from bad outputs. Existing methods often\nmiss key aspects like coherence, style, or relevance, or are biased by\npretraining data, making open-ended long-form evaluation an underexplored\nproblem. To address this gap, we propose PrefBERT, a scoring model for\nevaluating open-ended long-form generation in GRPO and guiding its training\nwith distinct rewards for good and bad outputs. Trai",
      "published_date": "2025-06-17T22:16:53+00:00",
      "collected_at": "2025-06-19T20:19:42.458921+00:00",
      "author": "",
      "source_priority": 1,
      "score": 94
    },
    {
      "id": "e518c9d1e51cfbf728fff80b3577258d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "LLaVA on a Budget: Multimodal AI with Limited Resources",
      "url": "https://towardsdatascience.com/llava-on-a-budget-multimodal-ai-with-limited-resources/",
      "description": "Let's get started with multimodality\nThe post LLaVA on a Budget: Multimodal AI with Limited Resources appeared first on Towards Data Science.",
      "published_date": "2025-06-17T18:06:11+00:00",
      "collected_at": "2025-06-19T20:19:43.930908+00:00",
      "author": "Marcello Politi",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "46fbbad38f9c13bbcad1ecdf41de7410",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Apply Sphinx’s Functionality to Create Documentation for Your Next Data Science Project",
      "url": "https://towardsdatascience.com/apply-sphinxs-functionality-to-create-documentation-for-your-next-data-science-project/",
      "description": "Three cases to use the Sphinx tool as a pro\nThe post Apply Sphinx’s Functionality to Create Documentation for Your Next Data Science Project appeared first on Towards Data Science.",
      "published_date": "2025-06-17T17:55:42+00:00",
      "collected_at": "2025-06-19T20:19:43.931109+00:00",
      "author": "Radmila Mandzhieva",
      "source_priority": 3,
      "score": 92
    },
    {
      "id": "23535b2f4318b27f71fcd30c6192cbee",
      "source_id": "pytorch_blog",
      "source": "Blog – PyTorch",
      "category": "Open Source",
      "title": "DeepNVMe: Affordable I/O scaling for Deep Learning Applications",
      "url": "https://pytorch.org/blog/deepnvme-affordable-i-o-scaling-for-deep-learning-applications/",
      "description": "Introduction We introduced DeepNVMe in summer 2024 as a suite of optimizations for tackling I/O bottlenecks in Deep Learning (DL). DeepNVMe delivers significant speedups for I/O bound DL workloads by leveraging storage...",
      "published_date": "2025-06-17T16:54:32+00:00",
      "collected_at": "2025-06-19T20:19:42.561184+00:00",
      "author": "Joe Mayer, Logan Adams, Olatunji Ruwase",
      "source_priority": 2,
      "score": 100
    },
    {
      "id": "1534d865569f6e929547b92c53d3c290",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "GMT: General Motion Tracking for Humanoid Whole-Body Control",
      "url": "https://arxiv.org/abs/2506.14770",
      "description": "The ability to track general whole-body motions in the real world is a useful\nway to build general-purpose humanoid robots. However, achieving this can be\nchallenging due to the temporal and kinematic diversity of the motions, the\npolicy's capability, and the difficulty of coordination of the upper and lower\nbodies. To address these issues, we propose GMT, a general and scalable\nmotion-tracking framework that trains a single unified policy to enable\nhumanoid robots to track diverse motions in th",
      "published_date": "2025-06-17T13:59:33+00:00",
      "collected_at": "2025-06-19T20:19:42.456813+00:00",
      "author": "",
      "source_priority": 1,
      "score": 93
    },
    {
      "id": "95021c78074287cb83591b3409952463",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents",
      "url": "https://arxiv.org/abs/2506.14866",
      "description": "Computer use agents are LLM-based agents that can directly interact with a\ngraphical user interface, by processing screenshots or accessibility trees.\nWhile these systems are gaining popularity, their safety has been largely\noverlooked, despite the fact that evaluating and understanding their potential\nfor harmful behavior is essential for widespread adoption. To address this gap,\nwe introduce OS-Harm, a new benchmark for measuring safety of computer use\nagents. OS-Harm is built on top of the OS",
      "published_date": "2025-06-17T13:59:31+00:00",
      "collected_at": "2025-06-19T20:19:42.458175+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "7db433699434c425abd7bfd49844ee9a",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal\n  Models",
      "url": "https://arxiv.org/abs/2506.14435",
      "description": "Large multimodal Mixture-of-Experts (MoEs) effectively scale the model size\nto boost performance while maintaining fixed active parameters. However,\nprevious works primarily utilized full-precision experts during sparse\nup-cycling. Despite they show superior performance on end tasks, the large\namount of experts introduces higher memory footprint, which poses significant\nchallenges for the deployment on edge devices. In this work, we propose MoTE, a\nscalable and memory-efficient approach to train",
      "published_date": "2025-06-17T07:53:49+00:00",
      "collected_at": "2025-06-19T20:19:42.459852+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "b148d646bfb135a6466ca6f9950f0689",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Grad-CAM from Scratch with PyTorch Hooks",
      "url": "https://towardsdatascience.com/grad-cam-from-scratch-with-pytorch-hooks/",
      "description": "A hands-on look at an explainable AI (XAI) technique that helps reveal why a convolutional neural network (CNN) made a particular decision\nThe post Grad-CAM from Scratch with PyTorch Hooks appeared first on Towards Data Science.",
      "published_date": "2025-06-17T05:52:18+00:00",
      "collected_at": "2025-06-19T20:19:43.931317+00:00",
      "author": "Conor O'Sullivan",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "404eca4e9be209de4968fa8eaa4c3801",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured\n  Proxies",
      "url": "https://arxiv.org/abs/2506.14315",
      "description": "Automatic creation of 3D scenes for immersive VR presence has been a\nsignificant research focus for decades. However, existing methods often rely on\neither high-poly mesh modeling with post-hoc simplification or massive 3D\nGaussians, resulting in a complex pipeline or limited visual realism. In this\npaper, we demonstrate that such exhaustive modeling is unnecessary for\nachieving compelling immersive experience. We introduce ImmerseGen, a novel\nagent-guided framework for compact and photorealisti",
      "published_date": "2025-06-17T04:50:05+00:00",
      "collected_at": "2025-06-19T20:19:42.457327+00:00",
      "author": "",
      "source_priority": 1,
      "score": 99
    },
    {
      "id": "64a085b2bc1f5ae0c1531550c3af00ee",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents",
      "url": "https://arxiv.org/abs/2506.14205",
      "description": "We introduce AgentSynth, a scalable and cost-efficient pipeline for\nautomatically synthesizing high-quality tasks and trajectory datasets for\ngeneralist computer-use agents. Leveraging information asymmetry, AgentSynth\nconstructs subtasks that are simple during generation but significantly more\nchallenging when composed into long-horizon tasks, enabling the creation of\nover 6,000 diverse and realistic tasks. Our pipeline begins with an LLM-based\ntask proposer guided by a persona, followed by an",
      "published_date": "2025-06-17T01:46:52+00:00",
      "collected_at": "2025-06-19T20:19:42.460855+00:00",
      "author": "",
      "source_priority": 1,
      "score": 100
    },
    {
      "id": "32d314415eaab25648b9084330e0895e",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "A Practical Starters’ Guide to Causal Structure Learning with Bayesian Methods in Python",
      "url": "https://towardsdatascience.com/a-practical-starters-guide-to-causal-structure-learning-with-bayesian-methods-in-python/",
      "description": "Learn Causal Structures and make inferences with Bayesian Methods: Python Tutorial\nThe post A Practical Starters’ Guide to Causal Structure Learning with Bayesian Methods in Python appeared first on Towards Data Science.",
      "published_date": "2025-06-17T00:45:46+00:00",
      "collected_at": "2025-06-19T20:19:43.931512+00:00",
      "author": "Erdogan Taskesen",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "3b18452ba89445f24ebc15f969f67868",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Let’s Analyze OpenAI’s Claims About ChatGPT Energy Use",
      "url": "https://towardsdatascience.com/lets-analyze-openais-claims-about-chatgpt-energy-use/",
      "description": "ChatGPT uses an average of 0.34 Wh per query, according to a blog post by Sam Altman. Does that figure hold up?\nThe post Let’s Analyze OpenAI’s Claims About ChatGPT Energy Use appeared first on Towards Data Science.",
      "published_date": "2025-06-16T19:31:58+00:00",
      "collected_at": "2025-06-19T20:19:43.931841+00:00",
      "author": "Kasper Groes Albin Ludvigsen",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "8d8888a67d52c0320ffd86cbc05ed4cb",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Regularisation: A Deep Dive into Theory, Implementation, and Practical Insights",
      "url": "https://towardsdatascience.com/regularisation-a-deep-dive-into-theory-implementation-and-practical-insights/",
      "description": "A detailed guide on controlling overfitting and increasing the stability of your models.\nThe post Regularisation: A Deep Dive into Theory, Implementation, and Practical Insights appeared first on Towards Data Science.",
      "published_date": "2025-06-16T19:16:38+00:00",
      "collected_at": "2025-06-19T20:19:43.932032+00:00",
      "author": "Sourav Mohile",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "a0092c46510f51961c64ac45063c699d",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Build an AI Agent to Explore Your Data Catalog with Natural Language",
      "url": "https://towardsdatascience.com/build-and-ai-agent-to-explore-your-data-catalog-with-natural-language/",
      "description": "Leverage LLMs to query your Databricks Data Catalog\nThe post Build an AI Agent to Explore Your Data Catalog with Natural Language appeared first on Towards Data Science.",
      "published_date": "2025-06-16T17:37:42+00:00",
      "collected_at": "2025-06-19T20:19:43.932214+00:00",
      "author": "Fabiana Clemente",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "38317db47248e6c73c6016a6ca7a648a",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "I Won $10,000 in a Machine Learning Competition — Here’s My Complete Strategy",
      "url": "https://towardsdatascience.com/i-won-10000-in-a-machine-learning-competition-heres-my-complete-strategy/",
      "description": "Complete guide to feature selection, threshold optimization, and neural network architecture for ML competitions\nThe post I Won $10,000 in a Machine Learning Competition — Here’s My Complete Strategy appeared first on Towards Data Science.",
      "published_date": "2025-06-16T17:12:24+00:00",
      "collected_at": "2025-06-19T20:19:43.932426+00:00",
      "author": "Claudia Ng",
      "source_priority": 3,
      "score": 100
    },
    {
      "id": "c3ad6fbaec8be7e9f6249a3c8589b100",
      "source_id": "towards_data_science",
      "source": "Towards Data Science",
      "category": "Open Source",
      "title": "Agents, APIs, and the Next Layer of the Internet",
      "url": "https://towardsdatascience.com/agents-apis-and-the-next-layer-of-the-internet/",
      "description": "Part I: Shipping Containers for Thought Every so often a simple idea rewires everything. The shipping container didn’t just optimise logistics; it flattened the globe, collapsed time zones, and rewrote the economics of trade. In its geometric austerity was a quiet revolution: standardisation. Similarly, HTML and HTTP didn’t invent information exchange — any more than […]\nThe post Agents, APIs, and the Next Layer of the Internet appeared first on Towards Data Science.",
      "published_date": "2025-06-16T17:06:00+00:00",
      "collected_at": "2025-06-19T20:19:43.932626+00:00",
      "author": "Cooper Doyle",
      "source_priority": 3,
      "score": 91
    },
    {
      "id": "771c89cbba88f3e643bdd223a561d156",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "BUT System for the MLC-SLM Challenge",
      "url": "https://arxiv.org/abs/2506.13414",
      "description": "We present a two-speaker automatic speech recognition (ASR) system that\ncombines DiCoW -- a diarization-conditioned variant of Whisper -- with\nDiariZen, a diarization pipeline built on top of Pyannote. We first evaluate\nboth systems in out-of-domain (OOD) multilingual scenarios without any\nfine-tuning. In this scenario, DiariZen consistently outperforms the baseline\nPyannote diarization model, demonstrating strong generalization. Despite being\nfine-tuned on English-only data for target-speaker A",
      "published_date": "2025-06-16T08:28:35+00:00",
      "collected_at": "2025-06-19T20:19:42.457646+00:00",
      "author": "",
      "source_priority": 1,
      "score": 92
    },
    {
      "id": "bc755f7f3f5c510f59b84dd3287380e7",
      "source_id": "huggingface_papers_api",
      "source": "huggingface_papers_api",
      "category": "Open Source",
      "title": "PictSure: Pretraining Embeddings Matters for In-Context Learning Image\n  Classifiers",
      "url": "https://arxiv.org/abs/2506.14842",
      "description": "Building image classification models remains cumbersome in data-scarce\ndomains, where collecting large labeled datasets is impractical. In-context\nlearning (ICL) has emerged as a promising paradigm for few-shot image\nclassification (FSIC), enabling models to generalize across domains without\ngradient-based adaptation. However, prior work has largely overlooked a\ncritical component of ICL-based FSIC pipelines: the role of image embeddings.\nIn this work, we present PictSure, an ICL framework that",
      "published_date": "2025-06-16T04:57:03+00:00",
      "collected_at": "2025-06-19T20:19:42.457054+00:00",
      "author": "",
      "source_priority": 1,
      "score": 91
    },
    {
      "id": "60c1fe34ea4d768996bae1b32a454c16",
      "source_id": "pytorch_blog",
      "source": "Blog – PyTorch",
      "category": "Open Source",
      "title": "ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization",
      "url": "https://pytorch.org/blog/paretoq-scaling-laws-in-extremely-low-bit-llm-quantization/",
      "description": "The field of large language models is shifting toward lower-precision computation. This shift necessitates a rethinking of scaling laws to account for the effects of quantization on resulting quantized model...",
      "published_date": "2025-06-13T18:43:38+00:00",
      "collected_at": "2025-06-19T20:19:42.561255+00:00",
      "author": "Zechun Liu, Changsheng Zhao, Hanxian Huang, Sijia Chen, Jing Zhang, Andrew Or, Jiawei Zhao, Scott Roy, Lisa Jin, Yunyang Xiong, Yangyang Shi, Lin Xiao, Yuandong Tian, Bilge Soran, Raghuraman Krishnamoorthi, Tijmen Blankevoort, Vikas Chandra (Meta)",
      "source_priority": 2,
      "score": 100
    }
  ],
  "updated": "2025-06-19T20:20:21.040026"
}